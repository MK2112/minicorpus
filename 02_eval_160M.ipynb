{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Pythia $160\\text{M}$ pre-trained on The Pile vs. Pythia $160\\text{M}$ trained on MiniPile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectives:\n",
    "- [x] Prepare (Download) two models - **Pythia $160M$ Untrained** and **Pythia $160M$ fully Pile-trained**\n",
    "- [x] Load MiniPile Dataset from disk\n",
    "- [x] Train **Pythia $160M$ Untrained** on MiniPile (according to the MiniPile paper) *and save the model* (`pythia160m_minipile_trained`)\n",
    "- [x] Evaluate the performance of **Pythia $160M$ Pile-trained** on MMLU, ARC, WinoGrande, HellaSwag, Lambada benchmarks\n",
    "- [x] Evaluate the performance of **Pythia $160M$ Untrained** on MMLU, ARC, WinoGrande, HellaSwag, Lambada benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages/huggingface_hub-0.26.2-py3.8.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting lm-eval\n",
      "  Downloading lm_eval-0.4.5-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from lm-eval) (1.1.1)\n",
      "Requirement already satisfied: evaluate in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from lm-eval) (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from lm-eval) (3.1.0)\n",
      "Collecting jsonlines (from lm-eval)\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: numexpr in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from lm-eval) (2.10.1)\n",
      "Collecting peft>=0.2.0 (from lm-eval)\n",
      "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pybind11>=2.6.2 (from lm-eval)\n",
      "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting pytablewriter (from lm-eval)\n",
      "  Downloading pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting rouge-score>=0.0.4 (from lm-eval)\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sacrebleu>=1.5.0 (from lm-eval)\n",
      "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from lm-eval) (1.5.2)\n",
      "Collecting sqlitedict (from lm-eval)\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.8 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from lm-eval) (2.5.1)\n",
      "Collecting tqdm-multiprocess (from lm-eval)\n",
      "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: transformers>=4.1 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from lm-eval) (4.46.2)\n",
      "Collecting zstandard (from lm-eval)\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: dill in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from lm-eval) (0.3.8)\n",
      "Collecting word2number (from lm-eval)\n",
      "  Downloading word2number-1.1.zip (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting more-itertools (from lm-eval)\n",
      "  Downloading more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from accelerate>=0.26.0->lm-eval) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from accelerate>=0.26.0->lm-eval) (24.2)\n",
      "Requirement already satisfied: psutil in /home/marcus/.local/lib/python3.12/site-packages (from accelerate>=0.26.0->lm-eval) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/marcus/.local/lib/python3.12/site-packages (from accelerate>=0.26.0->lm-eval) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages/huggingface_hub-0.26.2-py3.8.egg (from accelerate>=0.26.0->lm-eval) (0.26.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from accelerate>=0.26.0->lm-eval) (0.4.5)\n",
      "Requirement already satisfied: filelock in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (16.1.0)\n",
      "Requirement already satisfied: pandas in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (4.67.0)\n",
      "Requirement already satisfied: xxhash in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (2.0.2)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->lm-eval) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (3.10.5)\n",
      "Requirement already satisfied: responses<0.19 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from evaluate->lm-eval) (0.18.0)\n",
      "Collecting absl-py (from rouge-score>=0.0.4->lm-eval)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting nltk (from rouge-score>=0.0.4->lm-eval)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/marcus/.local/lib/python3.12/site-packages (from rouge-score>=0.0.4->lm-eval) (1.16.0)\n",
      "Collecting portalocker (from sacrebleu>=1.5.0->lm-eval)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: regex in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from sacrebleu>=1.5.0->lm-eval) (2024.9.11)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu>=1.5.0->lm-eval)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: colorama in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from sacrebleu>=1.5.0->lm-eval) (0.4.6)\n",
      "Collecting lxml (from sacrebleu>=1.5.0->lm-eval)\n",
      "  Downloading lxml-5.3.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from scikit-learn>=0.24.1->lm-eval) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from scikit-learn>=0.24.1->lm-eval) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from scikit-learn>=0.24.1->lm-eval) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (4.11.0)\n",
      "Requirement already satisfied: setuptools in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (1.13.1)\n",
      "Requirement already satisfied: networkx in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8->lm-eval) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from transformers>=4.1->lm-eval) (0.20.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/marcus/.local/lib/python3.12/site-packages (from jsonlines->lm-eval) (23.2.0)\n",
      "Collecting DataProperty<2,>=1.0.1 (from pytablewriter->lm-eval)\n",
      "  Downloading DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval)\n",
      "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval)\n",
      "  Downloading pathvalidate-3.2.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval)\n",
      "  Downloading tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval)\n",
      "  Downloading tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval)\n",
      "  Downloading typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->lm-eval) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->lm-eval) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.11.0)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /home/marcus/.local/lib/python3.12/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2018.9 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (2024.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/marcus/.local/lib/python3.12/site-packages (from jinja2->torch>=1.8->lm-eval) (2.1.5)\n",
      "Requirement already satisfied: click in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from nltk->rouge-score>=0.0.4->lm-eval) (8.1.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /mnt/storage/miniconda3/envs/minipile/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->lm-eval) (2024.2)\n",
      "Downloading lm_eval-0.4.5-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
      "Downloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
      "Downloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
      "Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
      "Downloading zstandard-0.23.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
      "Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
      "Downloading pathvalidate-3.2.1-py3-none-any.whl (23 kB)\n",
      "Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\n",
      "Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading lxml-5.3.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: rouge-score, sqlitedict, word2number\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=a5da87315b882d021f7bb35aecb3c17a69216eee951fb6913a6baa2d754118ad\n",
      "  Stored in directory: /home/marcus/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=ecb2330fe80841f474cd336aa4e2a0a9484de2331355de58aa0321cd1babb82a\n",
      "  Stored in directory: /home/marcus/.cache/pip/wheels/7a/6f/21/fc016aef45ffcabe27129a2252f061387cbf278d2086225a64\n",
      "  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=7866e170cb532c4db898175a15957e07196fb671b4b41f77dff868c6064a639e\n",
      "  Stored in directory: /home/marcus/.cache/pip/wheels/5b/79/fb/d25928e599c7e11fe4e00d32048cd74933f34a74c633d2aea6\n",
      "Successfully built rouge-score sqlitedict word2number\n",
      "Installing collected packages: word2number, sqlitedict, zstandard, tqdm-multiprocess, tcolorpy, tabulate, pybind11, portalocker, pathvalidate, nltk, more-itertools, mbstrdecoder, lxml, jsonlines, absl-py, typepy, sacrebleu, rouge-score, DataProperty, tabledata, peft, pytablewriter, lm-eval\n",
      "Successfully installed DataProperty-1.0.1 absl-py-2.1.0 jsonlines-4.0.0 lm-eval-0.4.5 lxml-5.3.0 mbstrdecoder-1.1.3 more-itertools-10.5.0 nltk-3.9.1 pathvalidate-3.2.1 peft-0.13.2 portalocker-2.10.1 pybind11-2.13.6 pytablewriter-1.2.0 rouge-score-0.1.2 sacrebleu-2.4.3 sqlitedict-2.1.0 tabledata-1.3.3 tabulate-0.9.0 tcolorpy-0.1.6 tqdm-multiprocess-0.0.11 typepy-1.3.2 word2number-1.1 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "#! pip install transformers datasets torch accelerate evaluate wandb\n",
    "! pip install lm-eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "from lm_eval import tasks, evaluator, utils\n",
    "from huggingface_hub import snapshot_download\n",
    "from transformers import AutoModelForSequenceClassification, pipeline, EvalPrediction\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/mnt/data\"\n",
    "base_path = Path(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Download Pythia $160\\text{M}$ Untrained and Pythia $160\\text{M}$ Pile-Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model(down_dir: str, target_folder: str, cache_folder: str, repo_id: str, branch: str = \"main\") -> None:\n",
    "    down_dir = Path(down_dir)\n",
    "    target_dir = down_dir / target_folder\n",
    "    cache_dir = down_dir / cache_folder\n",
    "\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Downloading {repo_id}/{branch}...\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            snapshot_download(\n",
    "                repo_id,\n",
    "                repo_type=\"model\",\n",
    "                revision=branch,\n",
    "                cache_dir=str(cache_dir),\n",
    "                local_dir=str(target_dir)\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Download attempt failed: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading EleutherAI/pythia-160m-deduped/step0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1b0d1eabde49ed8369aab54b458508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download_model(down_dir=base_dir, target_folder=\"pythia160m_dedup_untrained\", \n",
    "               cache_folder=\"pythia160m_dedup_untrained_Cache\",\n",
    "               repo_id=\"EleutherAI/pythia-160m-deduped\", branch=\"step0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading EleutherAI/pythia-160m-deduped/main...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05885cfd48b84224a27a9d653dfb305a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://huggingface.co/EleutherAI/pythia-160m/blob/main/README.md states:\n",
    "# \"[...] final step 143000 corresponds exactly to the model checkpoint on the main branch of each model.\"\n",
    "download_model(down_dir=base_dir, target_folder=\"pythia160m_dedup_pile\", \n",
    "               cache_folder=\"pythia160m_dedup_pile_Cache\",\n",
    "               repo_id=\"EleutherAI/pythia-160m-deduped\", branch=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load MiniPile Dataset from Disk\n",
    "\n",
    "We expect the MiniPile dataset to already have been downloaded to disk at an earlier point.<br>\n",
    "The logic for this can be found in the `01_get_piles` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading minipile train + val splits from the local directory \n",
    "# https://stackoverflow.com/questions/77020278/how-to-load-a-huggingface-dataset-from-local-path\n",
    "# https://github.com/MK2112/mobileYOLOv3/blob/main/mobileyolov3-cocotext.ipynb\n",
    "# Split is named exactly like with the original dataset https://huggingface.co/datasets/JeanKaddour/minipile\n",
    "minipile_train = load_dataset(\"parquet\",\n",
    "                              data_files={\n",
    "                                  \"train\": str(base_path / \"MiniPile\" / \"data\" / \"train-*.parquet\"),\n",
    "                                  \"validation\": str(base_path / \"MiniPile\" / \"data\" / \"validation-*.parquet\"),\n",
    "                                  \"test\": str(base_path / \"MiniPile\" / \"data\" / \"test-*.parquet\")\n",
    "                              },\n",
    "                              cache_dir=str(base_path / \"MiniPile_Cache\"),\n",
    "                              split=\"train\")\n",
    "\n",
    "minipile_val = load_dataset(\"parquet\",\n",
    "                            data_files={\n",
    "                                \"train\": str(base_path / \"MiniPile\" / \"data\" / \"train-*.parquet\"),\n",
    "                                \"validation\": str(base_path / \"MiniPile\" / \"data\" / \"validation-*.parquet\"),\n",
    "                                \"test\": str(base_path / \"MiniPile\" / \"data\" / \"test-*.parquet\")\n",
    "                            },\n",
    "                            cache_dir=str(base_path / \"MiniPile_Cache\"),\n",
    "                            split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hyperparameters for Pythia $160\\text{M}$ Untrained on MiniPile\n",
    "\n",
    "**Training Parameters for $160M$ for The Pile Deduplicated (*not* MiniPile)**<br>\n",
    "See [Pythia Paper](https://arxiv.org/abs/2304.01373) (p. 22) and [Pythia GitHub](https://github.com/EleutherAI/pythia/blob/main/models/160M/pythia-160m-deduped.yml):\n",
    "\n",
    "![](./img/pythia_train_params.png)\n",
    "\n",
    "- Each model gets exposed to $299,892,736,000 \\approx 300B$ tokens through training ($\\approx 1.5$ epochs on The Pile)\n",
    "- Batch size of $1024$ samples\n",
    "- Sequence length of $2048$\n",
    "- Adam optimizer with $\\beta_1 = 0.9$, $\\beta_2 = 0.95$, $\\epsilon = 1 \\times 10^{-8}$\n",
    "- Learning rates vary by model size:\n",
    "    - $70M$ model:  $10.0 \\times 10^{-4}$\n",
    "    - $160M$ model: $6.0 \\times 10^{-4}$\n",
    "    - $410M$ model: $3.0 \\times 10^{-4}$\n",
    "    - $1.0B$ model: $3.0 \\times 10^{-4}$\n",
    "    - $1.4B$ model: $2.0 \\times 10^{-4}$\n",
    "    - $2.8B$ model: $1.6 \\times 10^{-4}$\n",
    "    - $6.9B$ model: $1.2 \\times 10^{-4}$\n",
    "    - $12B$ model:  $1.2 \\times 10^{-4}$\n",
    "- train-iters $143000$\n",
    "- lr-decay-iters $143000$\n",
    "- lr-decay-style $\\text{cosine}$\n",
    "- lr-warmup $0.01$\n",
    "- weight-decay $0.01$\n",
    "- gradient-clipping $1.0$\n",
    "- lr-min $0.1 \\times \\text{optimizer.params.lr}$ (which isn't in the paper)\n",
    "- synchronize-each-layer $\\text{True}$ (i.e. gradients across all GPUs after each layer synced)\n",
    "- LR Scheduling: Decays to a minimum of $0.1\\times$ the maximum learning rate for all models\n",
    "- (Tokenizer is loaded as the same as for GPT-NeoX-20B)\n",
    "\n",
    "**Training Parameters for $160M$ for MiniPile**<br>\n",
    "See [MiniPile paper](https://arxiv.org/abs/2304.08442)\n",
    "- $1M/500/10k$ training/validation/test examples\n",
    "    - Vocab size: $32309614$\n",
    "    - Median document length: $294$\n",
    "    - Longest document length: $929633$\n",
    "\n",
    "**BERT Training Parameters for MiniPile**\n",
    "- Adam, $\\beta_1 = 0.9$, $\\beta_2 = 0.98$, $\\epsilon = 1 \\times 10^{-12}$\n",
    "- weight-decay $0.001$\n",
    "- One cycle policy with peak learning rate of $1 \\times 10^{-3}$\n",
    "- gradient-clipping $0.5$\n",
    "- Progressive batch size from $128$ to $4096$ with a linear increase over the course of training up to $300k$ steps, no warmup\n",
    "- $800k$ total training steps\n",
    "- weight averaging of the $k = 5$ latest checkpoints and $1k$ steps distance between them\n",
    "\n",
    "**T5 Training Parameters for MiniPile**\n",
    "- AdamW, matrix-wise LR scaling by its root mean square (RMS), no weight decay\n",
    "- base learning rate $0.02$\n",
    "- cosine schedule with final of $1 \\times 10^{-5}$\n",
    "- gradient-clipping $1.0$\n",
    "- batch size $288$\n",
    "- $10k$ warmup steps, $65536$ total training steps\n",
    "- weight averaging of the $k = 5$ latest checkpoints and $1k$ steps distance between them (akin to BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These training parameters are a good start, but they can only be interpreted as at most guiding, because they were applied for decoder-only and encoder-decoder models, yet not for pure decoder-only models like Pythia. Thus, if possible, one should look for approaches trained solely on MiniPile following the decoder-only paradigm for a more accurate guide to our own approach with Pythia. \n",
    "\n",
    "Luckily there exists a [GPT NeoX 122M MiniPile](https://huggingface.co/euclaise/gpt-neox-122m-minipile-digits) model that can be reverse-engineered for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped for version mismatch.\n"
     ]
    }
   ],
   "source": [
    "# Load the training arguments from the minipile-trained decode reference model GPT-NeoX-122M:\n",
    "# https://huggingface.co/euclaise/gpt-neox-122m-minipile-digits\n",
    "\n",
    "# Newer versions fail for missing attributes, 4.30.0 is documented to have been used\n",
    "if str(transformers.__version__) == \"4.30.0\":\n",
    "    training_args = torch.load(base_path / 'training_args_gptNEO122m.bin', weights_only=False)\n",
    "    output_file = 'train_args_gptNEO122m_minipile.txt'\n",
    "    try: \n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write(\"TrainingArguments attributes:\\n\")\n",
    "            for attr in dir(training_args):\n",
    "                if hasattr(training_args, attr) and not attr.startswith('_'):\n",
    "                    value = getattr(training_args, attr)\n",
    "                    f.write(f\"- {attr}: {value}\\n\")\n",
    "    except NameError as _:\n",
    "        pass # Fully ignore NameError, appears every time\n",
    "else:\n",
    "    print('Skipped for version mismatch.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GPTNeoX model card is a bit misleading, as it is stated that this model was trained exclusively on MiniPile. The tiny learning rate $5 \\times 10^{-6}$ with no weight decay implies a fine-tuning approach.\n",
    "\n",
    "I did this mostly to get a feeling for much the encoder-based model params deviate from the decoder-based model params.<br>\n",
    "I interpret the results as not too far off, e.g. we use the exact same learning rate and optimizer.<br>\n",
    "\n",
    "This implies that the training params on The Pile for Pythia $160M$ are a good starting point and we can scale these to accommodate the MiniPile dataset size and expect appropriate training effects.\n",
    "\n",
    "Core parameters are however not directly transferable: `train-iters` and therefore also `lr-decay-iters`.<br>\n",
    "For Pile deduplicated this was $143000$, but we have to scale this to the MiniPile dataset size, as the number of tokens processed by the model is crucial for the training process and could lead to overfitting and not accurately reflecting dataset knowledge retention capabilities if not adjusted properly.\n",
    "\n",
    "In other words, overshooting distorts dataset knowledge, while undershooting leads to underfitting and insufficient representation of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byte-based scale factor: 139.609153x\n",
      "MiniPile (scaled) Train-Iters/LR-Decay-Iters: 1024.288 ~ 1024\n"
     ]
    }
   ],
   "source": [
    "# I use the byte sizes as proxy for the number of tokens, as both datasets will get tokenized with the same tokenizer\n",
    "minipile_train_bytes = 5906108510 # see https://huggingface.co/datasets/JeanKaddour/minipile/blob/main/README.md\n",
    "pile_train_bytes = 824546807506   # see https://huggingface.co/datasets/EleutherAI/the_pile_deduplicated/blob/main/dataset_infos.json\n",
    "pile_effective_epochs = 1.5       # this many epochs are actually trained in the original model (calculation isn't affected, training params below are)\n",
    "\n",
    "scale_factor = (pile_train_bytes * pile_effective_epochs) / (minipile_train_bytes * pile_effective_epochs)\n",
    "print(f\"Byte-based scale factor: {scale_factor:10.6f}x\")\n",
    "print(f\"MiniPile (scaled) Train-Iters/LR-Decay-Iters: {143000 / scale_factor:.3f} ~ {round(143000 / scale_factor)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the $1024$ for training iterations may seem awkwardly small.<br>\n",
    "But, to reiterate, we strictly scaled it down iterations according to dataset size difference.\n",
    "\n",
    "While this may seem horrible in most other cases, as we thoroughly neuter exposure to data, this scale-correct limiting and overall lower exposure is exactly what we need here to operate relative to the original Pythia training. After all, the goal is to compare knowledge retention and generalization capabilities achievable on `The Pile Deduplicated` vs. the 'distilled' `MiniPile` under size-appropriate, similar conditions. Therefore, scaling the `train-iters` and therefore also `lr-decay-iters` using byte sizes as a proxy is actually appropriate here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now lay out the complete parameters:<br>\n",
    "With the three approach descriptions retrieved, we can take a more educated guess at the training params for Pythia $160M$ on MiniPile:\n",
    "\n",
    "- Adam optimizer (GPT NeoX and T5-Base MiniPile suggest the 'generally more stable' AdamW, but Pythia uses Adam so we keep it most similar)\n",
    "    - $\\beta_1 = 0.9$, $\\beta_2 = 0.95$, (Pythia)\n",
    "    - $\\epsilon = 1 \\times 10^{-8}$ (GPT NeoX and Pythia)\n",
    "    - learning rate $6 \\times 10^{-4}$ (Pythia)\n",
    "    - lr-schedule $\\text{cosine annealing}$ (Pythia)\n",
    "    - lr-warmup $0.01$ of total steps (Pythia)\n",
    "    - lr-min $0.1 \\times \\text{lr}$ (Pythia)\n",
    "    - weight-decay $1 \\times 10^{-2}$ (Pythia)\n",
    "- gradient-clipping $1.0$ (Pythia)\n",
    "- batch size $1024$ (Pythia, probably grad accum needed, expect multi-GPU)\n",
    "- sequence length $2048$ (Pythia)\n",
    "- **train-iters: $1024$ (MiniPile-specific)**\n",
    "- **lr-decay-iters: same as train-iters (MiniPile-specific)**\n",
    "- (won't do mixed precision for sake of most similar training conditions to Pile-trained Pythia)\n",
    "- (won't do weight averaging)\n",
    "- **Same GPT-NeoX-20B tokenizer as for Pythia-Pile**\n",
    "\n",
    "We can start training Pythia $160\\text{M}$ on MiniPile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Train Pythia $160\\text{M}$ Untrained on MiniPile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the untrained Pythia 160M tokenizer and model\n",
    "# https://stackoverflow.com/questions/64001128/load-a-pre-trained-model-from-disk-with-huggingface-transformers\n",
    "# Tokenizer is in fact a GPTNeoXTokenizer, only has a fast version available\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_path / \"pythia160m_dedup_untrained\", use_fast=True, local_files_only=True)\n",
    "empty_model = AutoModelForCausalLM.from_pretrained(base_path / \"pythia160m_dedup_untrained\", local_files_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pythia paper states a standard configuration where individual examples consist of up to $2048$ tokens.<br>\n",
    "This explains why the tokenizer doesn't contain a padding token, as the model is trained on variable-length sequences with this upper bound instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer doesn't have a pad token, use EOS as a substitute\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "def tokenize(example): \n",
    "    # seq_len = max_length = 2048 (as upper boundary, so not strict size -> no padding needed)\n",
    "    return tokenizer(example[\"text\"], \n",
    "                     truncation=True, \n",
    "                     max_length=2048,\n",
    "                     return_special_tokens_mask=True)\n",
    "\n",
    "if os.path.exists(base_path / \"minipile_train_tokenized\"):\n",
    "    minipile_train_tokenized = load_dataset(\"arrow\", data_files=str(base_path / \"minipile_train_tokenized/*.arrow\"), split=\"train\")\n",
    "    minipile_val_tokenized = load_dataset(\"arrow\", data_files=str(base_path / \"minipile_val_tokenized/*.arrow\"), split=\"train\")\n",
    "else:\n",
    "    minipile_train_tokenized = minipile_train.map(tokenize, batched=True, remove_columns=minipile_train.column_names) # retain only new fields from tokenization\n",
    "    minipile_val_tokenized = minipile_val.map(tokenize, batched=True, remove_columns=minipile_val.column_names)\n",
    "    minipile_train_tokenized.save_to_disk(base_path / \"minipile_train_tokenized\")\n",
    "    minipile_val_tokenized.save_to_disk(base_path / \"minipile_val_tokenized\")\n",
    "\n",
    "# Dynamic padding during training (mlm -> mask language model -> we're doing causal here)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: 1\n",
      "\n",
      "GPU 0:\tNVIDIA GeForce RTX 3060\n",
      "\tTotal memory:\t\t11.76 GiB\n",
      "\tAllocated memory:\t 0.00 GiB\n",
      "\tFree memory:\t\t11.76 GiB\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(f\"Available GPUs: {device_count}\")\n",
    "    for i in range(device_count):\n",
    "        device = torch.device(f'cuda:{i}')\n",
    "        device_properties = torch.cuda.get_device_properties(device)\n",
    "        total_mem = device_properties.total_memory / (1024 ** 3)\n",
    "        allocd_mem = torch.cuda.memory_allocated(device) / (1024 ** 3)\n",
    "        free_mem = total_mem - allocd_mem\n",
    "        print(f\"\\nGPU {i}:\\t{device_properties.name}\")\n",
    "        print(f\"\\tTotal memory:\\t\\t{total_mem:.2f} GiB\")\n",
    "        print(f\"\\tAllocated memory:\\t{allocd_mem:5.2f} GiB\")\n",
    "        print(f\"\\tFree memory:\\t\\t{free_mem:.2f} GiB\")\n",
    "else:\n",
    "    print(\"No CUDA-capable GPUs available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = str(base_path / \"pythia160m_minipile_trained\")\n",
    "log_dir = str(base_path / \"160m_minipile_logs\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# https://huggingface.co/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1.5,            # Since train_iters gets set, use num_train_epochs=1.5 like for The Pile\n",
    "    per_device_train_batch_size=4,   # Gives an effective batch size of 1024 after grad accum\n",
    "    per_device_eval_batch_size=4,    # Same as training batch size\n",
    "    gradient_accumulation_steps=256, # Achieve a batch size of 1024\n",
    "    learning_rate=6e-4,              # Default Pythia 160M\n",
    "    weight_decay=0.01,               # Default Pythia 160M\n",
    "    max_steps=1024,                  # Adjusted for MiniPile (https://discuss.huggingface.co/t/how-does-max-steps-affect-the-number-of-samples-the-model-sees/69681)\n",
    "    lr_scheduler_type=\"cosine\",      # As per Pythia 160M paper\n",
    "    warmup_steps=int(0.01 * 1024),   # 1% of total steps for warmup\n",
    "    logging_dir=log_dir,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,     # Frequency for evaluation during training\n",
    "    save_steps=1024,    # Save at the end of training\n",
    "    save_total_limit=1, # Only keep the most recent checkpoint\n",
    "    fp16=True,         # Not using mixed precision for comparable conditions\n",
    "    report_to=None,     # Noting this for later iterations, maybe set this as \"wandb\", \"tensorboard\" or smth\n",
    "    ddp_find_unused_parameters=False, # see https://discuss.pytorch.org/t/how-to-change-ddp-parameter-find-unused-parameters-true-to-false-during-training/130763\n",
    "    max_grad_norm=1.0,  # As per Pythia 160M paper\n",
    ")\n",
    "\n",
    "# Ensure training across multiple GPUs if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "empty_model = empty_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(empty_model.parameters(), lr=training_args.learning_rate, betas=(0.9, 0.95), eps=1e-8, weight_decay=0.01)\n",
    "\n",
    "# Train Pythia 160M Untrained on MiniPile\n",
    "# https://huggingface.co/docs/transformers/v4.46.0/en/main_classes/trainer\n",
    "trainer = Trainer(model=empty_model,\n",
    "                  args=training_args,\n",
    "                  train_dataset=minipile_train_tokenized,\n",
    "                  eval_dataset=minipile_val_tokenized,\n",
    "                  data_collator=data_collator,\n",
    "                  optimizers=(optimizer, None))\n",
    "\n",
    "scheduler = get_scheduler(name=training_args.lr_scheduler_type,\n",
    "                          optimizer=optimizer,\n",
    "                          num_warmup_steps=training_args.warmup_steps,\n",
    "                          num_training_steps=training_args.max_steps)\n",
    "\n",
    "num_batches = len(trainer.get_train_dataloader())  # Number of batches\n",
    "total_training_steps = num_batches * training_args.gradient_accumulation_steps * int(training_args.num_train_epochs)\n",
    "\n",
    "# Training loop with manual minimum learning rate enforcement\n",
    "for epoch in range(int(training_args.num_train_epochs)):\n",
    "    with tqdm(total=total_training_steps, desc=f\"Training Epoch {epoch + 1}/{int(training_args.num_train_epochs)}\") as pbar:\n",
    "        for _, batch in enumerate(trainer.get_train_dataloader()):\n",
    "            trainer.training_step(trainer.model, batch)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            for param_group in optimizer.param_groups:\n",
    "                # Manually ... ensure lr doesn't go below min_lr (Pythia wants this)\n",
    "                param_group['lr'] = max(param_group['lr'], 0.1 * training_args.learning_rate)\n",
    "            pbar.update(1)\n",
    "\n",
    "# Why is this a two-step process?!\n",
    "trainer.save_model(str(base_path / \"pythia160m_minipile_trained\")) # This saves the model weights\n",
    "tokenizer.save_pretrained(str(base_path / \"pythia160m_minipile_trained\")) # This saves the tokenizer (don't know if needed, better save than sorry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of Pythia $160\\text{M}$ on MiniPile was done on `gruenau8` with the `02_train_160M.py` script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluate Pythia $160\\text{M}$ MiniPile vs. Pythia $160\\text{M}$ Pile-Trained on Benchmarks\n",
    "\n",
    "### AI2 Reasoning Challenge (ARC-Challenge)\n",
    "[Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge (Clark, et al. 2018)](https://arxiv.org/abs/1803.05457#)\n",
    "- grade-school science questions, require reasoning efforts beyond just information retrieval\n",
    "- tests specifically for reaction to new concepts through cross-domain generalization\n",
    "- requires broader domain knowledge, reasoning capabilities and combinatory skills for responses\n",
    "- will help evaluate assessing whether a MiniPile-trained model retains *the flexibility and cross-domain generalization capabilities* of The Pile-trained model\n",
    "\n",
    "### Massive Multitask Language Understanding (MMLU)\n",
    "[Measuring Massive Multitask Language Understanding (Hendrycks, et al. 2021)](https://arxiv.org/abs/2009.03300)\n",
    "- comprehensive, inputs/examples span $57$ different tasks\n",
    "- specifically testing across *all* subjects\n",
    "- will help evaluate assessing whether a MiniPile-trained model retains *specifically the width of knowledge* of The Pile-trained model\n",
    "\n",
    "### HellaSwag\n",
    "[HellaSwag: Can a Machine *Really* Finish Your Sentence (Zellers, et al. 2019)](https://aclanthology.org/P19-1472.pdf)\n",
    "- presenting models with a situation and asking them to choose the most plausible continuation\n",
    "- I've seen in Karpathy's series, thus new it was applicable to decoder-only models and thus to Pythia\n",
    "- tests for context understanding, conversational capabilities and generalization\n",
    "\n",
    "### WinoGrande\n",
    "[WinoGrande: An Adversarial Winograd Schema Challenge at Scale (Sakaguchi, et al. 2019)](https://arxiv.org/abs/1907.10641)\n",
    "- testing the ability to determine pronouns based on commonsense reasoning\n",
    "- checks whether beyond dataset contents, the model can just as deeply perceive/learn language understanding and reasoning capabilities\n",
    "- helps us solve the question of whether reducing MiniPile to most relevant data with \"topic-selective k-Means\" still retains an overall language understanding\n",
    "\n",
    "### Language Model Benchmark for Autoregressive Data Analysis (Lambada (OpenAI))\n",
    "[The LAMBADA dataset: Word prediction requiring a broad discourse context (Paperno, et al. 2016)](https://arxiv.org/abs/1606.06031)\n",
    "- evaluates a model's ability to predict a last word of some text, where generating the right word requires long-range context understanding\n",
    "- tests for context understanding, conversational capabilities and generalization\n",
    "- not as directly applicable to our problem set here, but helps calibrate the benchmark pipeline, because numbers were reported for Pythia $160M$ on this benchmark\n",
    "- this in turn gives more credibility and a better look into the MiniPile Pythia's performance overall\n",
    "- maybe reducing dataset size can disturb long range context processing, this helps us evaluate that\n",
    "- using the OpenAI version for cross-referencability with the Pythia paper\n",
    "\n",
    "### Benchmark of Linguistic Minimal Pairs (BLiMP)\n",
    "[BLiMP: The Benchmark of Linguistic Minimal Pairs for English (Warstadt, et al. 2020)](https://arxiv.org/abs/1912.00582)\n",
    "- evaluates grammatical knowledge across $67$ distinct linguistic phenomena/subtasks in English\n",
    "- minimal pairs of sentences differing in grammaticality used to test fine-grained linguistic competence\n",
    "- helps signal if a model is capable of distinguishing grammatical and ungrammatical sentences $\\rightarrow$ What degree of language understanding is retained?\n",
    "- Useful for checking whether dataset reduction impacts capability to capture even subtle grammatical distinctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm_eval import utils, simple_evaluate\n",
    "from lm_eval.models.huggingface import HFLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:31:27,117 WARNING  [huggingface.py:95] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2024-11-18:16:31:27,118 INFO     [huggingface.py:481] Using model type 'default'\n",
      "2024-11-18:16:31:27,130 WARNING  [huggingface.py:275] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "2024-11-18:16:31:27,133 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2024-11-18:16:31:27,134 INFO     [evaluator.py:217] Using pre-initialized model\n",
      "2024-11-18:16:31:33,506 INFO     [__init__.py:459] The tag 'arc_ca' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-11-18:16:31:33,528 INFO     [__init__.py:459] The tag 'arc_ca' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873a741044944489a5072b0aa40e4dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128175a3981d4125819a246270138038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/190k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec7273cb4484bf580c28052cff1a14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/204k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbc2bcb11514b84bf34501893eea8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/55.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd2dccceee7427dbaf66f40637d355a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0dda4a8e0224ae1962b78d43ac8329e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1172 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b467679cd7459987863e023552acb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/299 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e0044e8f1c4af79740e68303753a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4383d4fb0344765a8de1aa535303935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mmlu_no_train.py:   0%|          | 0.00/5.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735570ef943b4bb78e2802569fb740bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data.tar:   0%|          | 0.00/166M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e66b028cb514b4f89e9c623fd765aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78769c04ecba4d4cb2fc9da79293f0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8ebf8a710d449e8a2216aac7e65e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fd687f30444f17a9a3c458964027ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10807bcedf4426b974c4e8ed6ad9268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af29fd8e546048c0b7ce8eb097138ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5c29f56d4f4ab58ddaedecae9609c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851ab9ceeaf741ac83409e587beb25b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d4eddc04a746b0ad70deb4659f2080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4977b82a1494752945e15ac95a6f0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7616d22d7e5b4b22a0a7081087c5c2ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454915fdc0b24a36b0a4a5e76ac12a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431baa9fc9764f41bcccd064bd5f1908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be922dfa6e2487ba79568b06b97cc85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5867f89ae8774db2a8638ebb64f6a97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b57cb825b3d4bc0a9ae3831fe9711d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aca1bdb9e964bf288ec04ee165b20cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8295f8617f84837841bd0cb2ee6a846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6af354dd1224eb19dfd97a5544c5917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77cf3eb96804e73a56254aebff72806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a292198dc749a1bdffbf4ae777b294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44b8de480c9449cb862184d98fcd886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9381fa80a6047d0bfa8b5d5e819cc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e64c69202c45cb8359960a9bc6c933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dfaac7882734ea2b9e1bf553c64e66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b20f5e95a24b3b94842bcfbc8492c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53525b6dbd7749be84bbc98286f235c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5812a2ff9f0d499daaad3e03c85236bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e479707ab440459d6c83cc7723f63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3736ba4c1f416198cb117e5d4b2700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323d0d33ac2945ee88681ffb5529f8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6474c257de7e46d6928243a1c2083e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1371f418151347289afab4c88a4424ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34020986528840958fb62dd42d1f3bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745f73a29bdd4f269ad4e4524c9e73e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f797cab7b04fa28bca1e7ffc04b782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98728d89c0a430291597f890972769f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905cfc9131de4e4b8087d7b8ca22fdfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2c5fe29e194c0bbdd1ef5c32cd1ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d20d01054ce4897afe5f33179514a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c4533891af4cbbaec80d12cb9e143e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fe31c77a7d4b688c691b7c15878d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773ff680dbca48709bb9e7761e6d9557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b3557aaf0347169c7216adaceaf86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c3e87bc3ee436ca105250cbb011c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81278c0db72460c9f9149a8a463ebdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffdb5c0d6444c8ca2a6f630603bd3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d77fad1a77049e18d23dd8037c24251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e468ed43cd5040c89c0c72e9723f557c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2169e303f30345bfbcc2f99a6714501f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cfdc42186a64fadbbf3875a748b909b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2715369f46ff43bf89e868b342b4f6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdad87e3dec44cbb12d814d7627d93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e0dcd51ef54ae0ad7bfa6fe13a371e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7d841d515449c7bb62665c8cb55dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253a6973497f4d9890227351d3e22854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0492e372df184a1683fd17f3c264304a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c960e3b2ab248e3bc42d3b00f3fb3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe282982bec4290a8f33cf4e18aeccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cce2703c8943b781f44006f5a0ed55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6a9383c8f3417a85edffa0ba3e0262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e632a03d8f045c2876de26fdaa3efbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6563afcddcb14333a5520b59b10f64b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf6a1971283449da8e204cc5b6f4766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f854d0f419e44a0c8cdb6c7844b16cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8542ffcd8db5411a875d5dfe569a0642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4cbc4c515d948e38afe1ab084fa8581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac56dc6f0a14b3cb89ddc275585be22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cc54a25f50415a976827989e790f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b82cea9a11b46c5b2ea4715bf8433db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00013e372cea49918ad6457b990b1eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61661a9788da4a9480cb0a3f6beba4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c7210140c84194a4b28125a920009e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2893ff26f5574ca2973c07d709bdfc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0460d50f0e64218ac56d32b794d0606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7bbd0f7326477783c75105b1161494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8e33cb3c004670b051df68abf7dece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e9064b52f043be89e4d694e6e99980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f25edbfba7b4e5db9cc9c55a49073ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e269a2ac1e4aecba8c6ad019c12c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753e3d0d5404496ebae432ef57f80c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0581508f454e72be70f633ffab9dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37fd8c8f689543f4a8262aaf2756602e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a3e34463d148569380d12da1f58334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba7d44bac344f68a06ee4d56b546685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af94e8afe78e4be998592b68cadcc284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0953c08f494e4339923a60b2e769697e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37f0128b66e4abb89de8502e53c0cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc763203b464eb2b67c8022bf3b0a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3324501943a4f7caf4171d90d62faa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aebcaf4e34a4eaf8a69eda6a4e8a5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223ef054e589447b86c72171c92d3eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36514d0c24724e5ba70d8640cc0f928a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e23747dbb974d73978e2f91c29d76e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0219e15879c14030927c32fcf7b4a633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8d2438fbea4311a49fc3a8f8fbed22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b8a8d9f3d8479f9a00f465da5a3fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaca4e6f077d412ebb84f57fec9d455e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70a26b5ea70414ba4ebabebacf2fb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29892094ee884e20b78ce57760928697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2878d3a06d7848208f4aafcd718efcfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e415f7d15694915b6529cb00ccc4f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ba7cd4967b4a4092c8b3c860736a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188f8bdedf9943d18a8daef7e2723ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4e7841813f4cb298bd1369bc3de9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ea9fb0a3684b98a6a687e7c83d9b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b805f8a6874242d9bca6f9c212f70f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10bd830ef394284b795eb1af46f4cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc5e114d5e54dd0a5e15ffcf749123a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628ab7dae9b54a538a63ed34afc3167f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcfda833a1e4543afe7ed982cf91083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fdbfff6527541db952124409e66f45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6783be8e6574742aa4dbcebc959e9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0d9e4ee74b489189be70215c8ccd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd816bec5524e83af73a2ed74db8458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd937d7cc71f4b349647f5af1fb0cd19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d00a58febe4797af4303f2add9d8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bedc9f9f7fc44de8d9e5143498be7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2982cfc000b4677b41b8cb95b113e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e423ae4303174c08a07aa8c8f2a9a109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b689db8ee04eb89163faa77a08668b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1515895e3984ae09036c8d5fdf59ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57939c21bdd5467bb0bb012f1c9fab73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc77f6e379849ceb2157d0f3064d549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c11c19ba5d4b64b5fd546cdaf4a292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059a520477f3462480c82c1191af7d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9773b7efd76343c7972fdbec9e1ee6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2796649203e74139833ef1dafc89b12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91c9ca76cd5475b918f3cca0f9c2454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cab20c0866c48e3a817f6a10f9c76a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16c957e512c48b892fa4526e7db7999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a25e680065f4d41b3d7db0965aa0f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c3c591d3414f56a48fb50cec6ebf89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba28e23b7e1e42caac72efee3be40e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b88fecd051d41aeac63c65267586be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880cd30ee34541fc96ac159ce5d4b392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13413addc48e472b9a40718b12f2d527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c92d567f3e4c2c8654d9039459c184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef2b7705404487a855d158d93fd177f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d536b00a9d4a8fbdce437f87a6497c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce51f544e0af49319d52966c55e8cecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e094e1b7d8f45249350cb253ff9370e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d663feca974e95848026bcc2e27297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe66f7d38ad482daf1b1ad707e4e891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6699b7aec61740b49fb34301147c94cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47f8787a3504314ad24cf80759e6800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049ce2fd79b448bfa04122a61819b9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bbbb4a3dae4ebe80716a2dc4033935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b41f5c26c844a17b0f5e8abc32c3679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6eafc706694506bbac484941c757d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a76ed7a7dd4edfbe38445512a5992d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96eed24049174040b10051838f46debe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96378f91166a45a292aacf7c1b5c22fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ec73ac18154fcba572ed531ca74195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fa7c6e02a545d793cf993cd41c8f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1664a9097f5e41eea6e1048f33079761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27754e36ca044fd2a0618fccd8ce0006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1543ad4f4ff4118ad1b6acf0590d1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf738063f8d4995ac8a3510e23f9e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296cf31541804653b128ebc1dcbe73a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a05a1d807274321b15d45dd1dbf1dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc3d8f2747e42e39cb953571bb2436c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f54086db154e5a825a38ae00b79ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83571f191ff94fa1b005f4c982118949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd21c470897c4e6889e0b16823fe3a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b732a14b534f79854a90dea520efd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a1e16248154d79ba91f13a1f8192d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00671887a4f3498183d643bc2e031c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b7f8c4d1384bb4b0a6fd7a29c213ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f7a08b20bb4e92831101ba108d1691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75723ab100b34c66aabb6f71741cefe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2550da6ac9d4ffb88acba4a1966dbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8dfed398c7c473bb754b4ef548cdd08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "winogrande.py:   0%|          | 0.00/5.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40d974053d24b518caa7631617dec9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0120feebae1a46578a291d618c1e10e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/40398 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50400ea307a346a4995d141ea057e7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1767 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0847de51fff45d182eb48d0f9d1f118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1267 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb82abf248164f2c95333ea8923ec861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/6.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3bdf290ba14207a2fb7a191f16dbbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hellaswag.py:   0%|          | 0.00/4.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a266e4d74a54a908b85720420bda890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset_infos.json:   0%|          | 0.00/2.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428dfc2806b64fe1874bc8ce43db3c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/47.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49585488ecb46e7a4c846a976634ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/11.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9d5cad6a5946f080d6ee68d2c7f255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/12.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0881a372993440ba57d5817ee036cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/39905 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d36780dfb344a4e9ccaf3000d57fa30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc0a15efba047c3bb870cee02901cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3739fe75d154c6da0f10d23f7e3a840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/39905 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6e2985a2be4a4399106a3c95025b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef3ceb7cb004503a0c4cbba9a17cf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.99k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620f86b8b0fd4c21bbd1ec1bd981abe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lambada_openai.py:   0%|          | 0.00/4.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eda70e545e74b0ba57f7bf0456096c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0000.parquet:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8f0be287fc4288b257cd8f0de86b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5153 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:34:00,060 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-11-18:16:34:00,061 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e0dfab4cce4c59a63ed125b9e9905f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34aaf4647fc4707949cb68879c587cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00002.parquet:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2428ee4d7dd44fd3b02fa469476db3af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00002.parquet:   0%|          | 0.00/281M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541db5e5d6f349aba7cf26ff7062ee6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcbef70a06d4468b9644cb02d569d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b25c250973e47918c1491a5508cdb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f81a7e01b1424782e41f8dfef8bb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5153 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c20042daae42a8a9ea047cca3b00f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/4869 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:34:36,477 WARNING  [task.py:799] [Task: blimp_wh_vs_that_with_gap_long_distance] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:34:36,478 WARNING  [task.py:811] [Task: blimp_wh_vs_that_with_gap_long_distance] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdf494d26c84369b3325c5336e625bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/58.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1d579eb7924834a88e4a22680326ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/84.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8165a6a82f84105a18022e47e21fc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:34:41,881 WARNING  [task.py:799] [Task: blimp_wh_vs_that_with_gap] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:34:41,882 WARNING  [task.py:811] [Task: blimp_wh_vs_that_with_gap] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a133adb8c14245aed924c72f58638f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/60.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f31f274d0a54c288b29736fc6095af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:34:46,132 WARNING  [task.py:799] [Task: blimp_wh_vs_that_no_gap_long_distance] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:34:46,133 WARNING  [task.py:811] [Task: blimp_wh_vs_that_no_gap_long_distance] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197ec06572fb4718995f0db8fe9afaa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/95.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de8039be4714c6aac9c77c97eae049a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:34:49,347 WARNING  [task.py:799] [Task: blimp_wh_vs_that_no_gap] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:34:49,348 WARNING  [task.py:811] [Task: blimp_wh_vs_that_no_gap] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705b89ad2c1f4054bae57dc9f1a52ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/71.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be687a3e83e1406d9cffe3e8d9fa8d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:34:52,749 WARNING  [task.py:799] [Task: blimp_wh_questions_subject_gap_long_distance] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:34:52,750 WARNING  [task.py:811] [Task: blimp_wh_questions_subject_gap_long_distance] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f0874830f048e1968a47b46c2f5047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/98.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda0b87e7e4e449ba676ba064b58fde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:34:56,665 WARNING  [task.py:799] [Task: blimp_wh_questions_subject_gap] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:34:56,667 WARNING  [task.py:811] [Task: blimp_wh_questions_subject_gap] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da0262cb9f24ce2b32472f5e5a07b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/71.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b6f3bb3f044abc929d9188b747069c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:34:59,893 WARNING  [task.py:799] [Task: blimp_wh_questions_object_gap] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:34:59,894 WARNING  [task.py:811] [Task: blimp_wh_questions_object_gap] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05673466c0e84984ab94c7a28a1f1915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/70.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb05b32ab0d743b896cd190fe2a91e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:03,193 WARNING  [task.py:799] [Task: blimp_wh_island] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:03,194 WARNING  [task.py:811] [Task: blimp_wh_island] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d801a4279c7a4a87ae58fff64cf0a8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/52.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af262900c1254bb2b5137cabb591b94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:06,692 WARNING  [task.py:799] [Task: blimp_transitive] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:06,693 WARNING  [task.py:811] [Task: blimp_transitive] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aaceb6c4a2944349ba2ef55a444f247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/55.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de67058844f545e181c94a2d82d1f455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:13,717 WARNING  [task.py:799] [Task: blimp_tough_vs_raising_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:13,719 WARNING  [task.py:811] [Task: blimp_tough_vs_raising_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3650ce9d744f3c83fa069f51eb0945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/61.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e996cfe77f41414ba76e21083aa8093e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:17,171 WARNING  [task.py:799] [Task: blimp_tough_vs_raising_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:17,172 WARNING  [task.py:811] [Task: blimp_tough_vs_raising_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea721286efe48edba4110de0122a0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/44.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3106fca29d54a92bef28b1c745e1ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:20,397 WARNING  [task.py:799] [Task: blimp_superlative_quantifiers_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:20,398 WARNING  [task.py:811] [Task: blimp_superlative_quantifiers_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc510bbc3144a5fa980681da3b91188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438824c6177a47c5bb7c8a372a119e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:23,729 WARNING  [task.py:799] [Task: blimp_superlative_quantifiers_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:23,730 WARNING  [task.py:811] [Task: blimp_superlative_quantifiers_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab5a0fcd0fd4ab7a5786b284642ad73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/48.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fb6bcd381e40619e4fea413ca6a685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:27,053 WARNING  [task.py:799] [Task: blimp_sentential_subject_island] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:27,055 WARNING  [task.py:811] [Task: blimp_sentential_subject_island] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159cd647ae224820bceffe6293b18504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/56.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7087afeff04b4527825333ceaa9c1b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:30,233 WARNING  [task.py:799] [Task: blimp_sentential_negation_npi_scope] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:30,234 WARNING  [task.py:811] [Task: blimp_sentential_negation_npi_scope] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84dccac2a0a745149dbe7e5d4e0367f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/90.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda5cb9a12e2429c8ae211434848e6ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:33,854 WARNING  [task.py:799] [Task: blimp_sentential_negation_npi_licensor_present] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:33,855 WARNING  [task.py:811] [Task: blimp_sentential_negation_npi_licensor_present] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c131a144830483ebd38ea16da6fe340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/54.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d37a03d872d4d4ebc3515c56b30606e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:37,516 WARNING  [task.py:799] [Task: blimp_regular_plural_subject_verb_agreement_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:37,517 WARNING  [task.py:811] [Task: blimp_regular_plural_subject_verb_agreement_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183eb9edfcc4408c957663b19e7f3549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/43.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c88195a5c541a3813c5f85a1be8057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:40,875 WARNING  [task.py:799] [Task: blimp_regular_plural_subject_verb_agreement_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:40,876 WARNING  [task.py:811] [Task: blimp_regular_plural_subject_verb_agreement_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdaddb6fda6047e4afa30e5fe3cc4a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/49.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200a580469ac4512bc26473b39ad8ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:44,070 WARNING  [task.py:799] [Task: blimp_principle_A_reconstruction] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:44,071 WARNING  [task.py:811] [Task: blimp_principle_A_reconstruction] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5951837be98e4ee285f033824db95525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/44.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b732fc7ca50443cb2123243dcec4353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:47,433 WARNING  [task.py:799] [Task: blimp_principle_A_domain_3] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:47,434 WARNING  [task.py:811] [Task: blimp_principle_A_domain_3] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea5906f55e14ccb8dff2120bdbb87d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/52.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139969e2f88d403981de6b945eb4bec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:50,663 WARNING  [task.py:799] [Task: blimp_principle_A_domain_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:50,664 WARNING  [task.py:811] [Task: blimp_principle_A_domain_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af9fbf1d8d542bfb761970b38b798f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/58.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65fe24a9b8e4a9bb4bc8de9f4e77314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:53,783 WARNING  [task.py:799] [Task: blimp_principle_A_domain_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:53,784 WARNING  [task.py:811] [Task: blimp_principle_A_domain_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5221eb6c9f4675aa0a35dbb1c0ddc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/59.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a68e55d4a048cfafd0b2495419118a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:35:56,935 WARNING  [task.py:799] [Task: blimp_principle_A_case_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:35:56,937 WARNING  [task.py:811] [Task: blimp_principle_A_case_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389a7936b9e54055833ca9514cc85462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/56.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9edf1fd5e047b98768ebaa0ff1f4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:00,115 WARNING  [task.py:799] [Task: blimp_principle_A_case_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:00,116 WARNING  [task.py:811] [Task: blimp_principle_A_case_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8436398c9484b99bc4fe40b0ddd1cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/61.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5790f7076c14fa58f6f1fc0cc416f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:03,614 WARNING  [task.py:799] [Task: blimp_principle_A_c_command] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:03,615 WARNING  [task.py:811] [Task: blimp_principle_A_c_command] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa185b43fb244f18e88546d37dd5229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/67.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0be02bdf78445f824eec007e7cd5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:06,824 WARNING  [task.py:799] [Task: blimp_passive_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:06,824 WARNING  [task.py:811] [Task: blimp_passive_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2c7fdb2ad44d81a29ee98620d7e1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/40.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a978306dca4a239e5668ec64e5e777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:09,993 WARNING  [task.py:799] [Task: blimp_passive_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:09,994 WARNING  [task.py:811] [Task: blimp_passive_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f669f15dd8874a28be0e1dafe9be7825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/53.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5e3986c109481caad81508c5730299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:13,334 WARNING  [task.py:799] [Task: blimp_only_npi_scope] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:13,336 WARNING  [task.py:811] [Task: blimp_only_npi_scope] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7771deb15d4dcbabbdb5946971d86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/85.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7096978740467f87f9bab1012dd9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:16,553 WARNING  [task.py:799] [Task: blimp_only_npi_licensor_present] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:16,554 WARNING  [task.py:811] [Task: blimp_only_npi_licensor_present] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9312f36f331944599bccb38c314587af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/51.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a26e458b3d49b886f08d4f57cc873c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:19,734 WARNING  [task.py:799] [Task: blimp_npi_present_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:19,735 WARNING  [task.py:811] [Task: blimp_npi_present_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ec6326e3524d84aca817989631fc19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/51.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277e8efbe40c4448873e8ae5804a2aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:23,217 WARNING  [task.py:799] [Task: blimp_npi_present_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:23,218 WARNING  [task.py:811] [Task: blimp_npi_present_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28f5918aa6848208e0129eb8de4f0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/52.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e5849f7f7c48dc8540295748f5d28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:26,696 WARNING  [task.py:799] [Task: blimp_matrix_question_npi_licensor_present] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:26,698 WARNING  [task.py:811] [Task: blimp_matrix_question_npi_licensor_present] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f20b83013ca4c2483155ecade275745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/51.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c9ce4ec5304b2291b8514ec97a9332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:29,952 WARNING  [task.py:799] [Task: blimp_left_branch_island_simple_question] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:29,954 WARNING  [task.py:811] [Task: blimp_left_branch_island_simple_question] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f5070880604a6190641543b482bf48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/50.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9223203161424a5783a4e3bc7d44f05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:33,454 WARNING  [task.py:799] [Task: blimp_left_branch_island_echo_question] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:33,455 WARNING  [task.py:811] [Task: blimp_left_branch_island_echo_question] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dadeaa3ee42c43e5b6ef96a03e74ded3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc62da78b5b34c5db0c44a7257ec8502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:37,115 WARNING  [task.py:799] [Task: blimp_irregular_plural_subject_verb_agreement_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:37,116 WARNING  [task.py:811] [Task: blimp_irregular_plural_subject_verb_agreement_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd3e17347bf4b1e9912ab50938df76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/42.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b528a8f403548e2b79538edf062b104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:40,379 WARNING  [task.py:799] [Task: blimp_irregular_plural_subject_verb_agreement_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:40,380 WARNING  [task.py:811] [Task: blimp_irregular_plural_subject_verb_agreement_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cd0dea5f214725ab9126807f36dbde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/50.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6da3af9b3c43d8b3e219d4b073caf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:43,934 WARNING  [task.py:799] [Task: blimp_irregular_past_participle_verbs] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:43,935 WARNING  [task.py:811] [Task: blimp_irregular_past_participle_verbs] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a7cd01f4eb40c0a74be2bab74c6c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/37.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a281f4376994400862b313a39e1c8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:47,321 WARNING  [task.py:799] [Task: blimp_irregular_past_participle_adjectives] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:47,322 WARNING  [task.py:811] [Task: blimp_irregular_past_participle_adjectives] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f83d6c10e43424d8662f2bf8b955af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/36.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4a64df758c44f8a57d845298e04575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:50,480 WARNING  [task.py:799] [Task: blimp_intransitive] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:50,481 WARNING  [task.py:811] [Task: blimp_intransitive] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7e31ab4142499a852a9aee3876af09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/42.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629dc20bf520492295c40b94e6067c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:53,704 WARNING  [task.py:799] [Task: blimp_inchoative] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:53,705 WARNING  [task.py:811] [Task: blimp_inchoative] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ab1a7e972f459bb6d99d55684ff4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/39.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e197694caa4192ae5d3a2a4d0b3f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:36:57,186 WARNING  [task.py:799] [Task: blimp_expletive_it_object_raising] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:36:57,187 WARNING  [task.py:811] [Task: blimp_expletive_it_object_raising] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02be3a50ac6b41969bf3f1d964b546e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/88.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9864b3b9144ce79010d4af8d547c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:00,493 WARNING  [task.py:799] [Task: blimp_existential_there_subject_raising] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:00,494 WARNING  [task.py:811] [Task: blimp_existential_there_subject_raising] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d69538eaa541c6ab793f7706d446be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/59.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d265994912cc45c3a09d2f948e67c3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:03,800 WARNING  [task.py:799] [Task: blimp_existential_there_quantifiers_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:03,801 WARNING  [task.py:811] [Task: blimp_existential_there_quantifiers_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e09093877148edbb6156a6c2b055c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/52.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f69fd665d143ecbfe801263def8f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:06,974 WARNING  [task.py:799] [Task: blimp_existential_there_quantifiers_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:06,975 WARNING  [task.py:811] [Task: blimp_existential_there_quantifiers_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee80dd19a4240e0b026bfa0dcf6510c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/51.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f4ff5b5fdb4a6ca98147d206b3397f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:10,706 WARNING  [task.py:799] [Task: blimp_existential_there_object_raising] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:10,707 WARNING  [task.py:811] [Task: blimp_existential_there_object_raising] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f9470717414fa2b6929edf3842785f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/76.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5507829d9446069a11d0e45f8614b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:13,973 WARNING  [task.py:799] [Task: blimp_ellipsis_n_bar_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:13,975 WARNING  [task.py:811] [Task: blimp_ellipsis_n_bar_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404a6789844d4d09bc954a379b4120d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/98.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f7c20c9e6a4fc8a59b39397234dd22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:17,118 WARNING  [task.py:799] [Task: blimp_ellipsis_n_bar_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:17,119 WARNING  [task.py:811] [Task: blimp_ellipsis_n_bar_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76521f7e82c453288103a78310da109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/92.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779fc98f9d464232b2ad8e218f8b2ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:20,285 WARNING  [task.py:799] [Task: blimp_drop_argument] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:20,286 WARNING  [task.py:811] [Task: blimp_drop_argument] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb4f941c55748169b93ad54f3cd16f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/40.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b21a069ad84409391366da8f9d3503d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:23,585 WARNING  [task.py:799] [Task: blimp_distractor_agreement_relative_clause] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:23,586 WARNING  [task.py:811] [Task: blimp_distractor_agreement_relative_clause] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440caa0c307145758d53c0613cb91e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/77.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7801382c864da69873c0101916c6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:26,831 WARNING  [task.py:799] [Task: blimp_distractor_agreement_relational_noun] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:26,832 WARNING  [task.py:811] [Task: blimp_distractor_agreement_relational_noun] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e148f250a0493e92f052f4f5d63c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/59.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85757ddecfa648048ffe534d9981d2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:30,197 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_with_adjective_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:30,198 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_with_adjective_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4db421f36d4437a2fa26365b34ff2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/55.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8abcfcf667e4099b3c59c2e18fd817a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:33,419 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_with_adj_irregular_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:33,420 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_with_adj_irregular_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45daece4091c49a284bc22f607de660c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/54.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a41eb9fb9c4452a99acd9ae3a968e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:37,008 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_with_adj_irregular_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:37,009 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_with_adj_irregular_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6a6b76b486424189c64114745c2d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/54.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa04723fc694820a44dbf1f457f68e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:40,215 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_with_adj_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:40,216 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_with_adj_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d23bef92cbe4dc4b431f81972130e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/56.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf88af2d5734b3aab2d4d4975dfe417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:43,730 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_irregular_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:43,731 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_irregular_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f2dbe40fda4606aa644161584cd45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/47.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02dfb2de984041238133fac66c4e9308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:47,204 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_irregular_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:47,205 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_irregular_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c7ba786aa74be094149a9f2df49185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/47.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64b8169219a4ed8a661361f3f648113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:50,451 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:50,452 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f652601926784152aea7469b49ba7bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/49.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174dd42352c54556a50e0a600a88867e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:53,728 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:53,729 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5462a4fd5300474a94bf4101822d1cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/49.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5353d291a5e4a0daa63c88d26a4b608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:37:57,307 WARNING  [task.py:799] [Task: blimp_coordinate_structure_constraint_object_extraction] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:37:57,308 WARNING  [task.py:811] [Task: blimp_coordinate_structure_constraint_object_extraction] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b43205634564dfb880893eed7d99ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/51.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db7a2618945427f988a75ec29026050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:38:00,562 WARNING  [task.py:799] [Task: blimp_coordinate_structure_constraint_complex_left_branch] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:38:00,563 WARNING  [task.py:811] [Task: blimp_coordinate_structure_constraint_complex_left_branch] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac67d004fbf4164b645d74b65b9b748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/67.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5582d664a9343b782876b05392196a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:38:03,798 WARNING  [task.py:799] [Task: blimp_complex_NP_island] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:38:03,799 WARNING  [task.py:811] [Task: blimp_complex_NP_island] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628f36d521ea4011a98424d7770f2746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/78.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208b946bd6fd44458084961755ae9a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:38:06,983 WARNING  [task.py:799] [Task: blimp_causative] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:38:06,984 WARNING  [task.py:811] [Task: blimp_causative] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e1c930afcf47569a14ecddb04906fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/49.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fc6a3756964a0fb5870562e342f73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:38:10,189 WARNING  [task.py:799] [Task: blimp_animate_subject_trans] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:38:10,189 WARNING  [task.py:811] [Task: blimp_animate_subject_trans] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da01815ad624097909cf45f0432a2a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/49.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923b5881a3994e878b98ba93d45a040e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:38:13,437 WARNING  [task.py:799] [Task: blimp_animate_subject_passive] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:38:13,438 WARNING  [task.py:811] [Task: blimp_animate_subject_passive] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0752e2e7f83b4f388de4e54c79a45618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/47.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb23e2176cd446a8e12ec9a42919b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:38:17,224 WARNING  [task.py:799] [Task: blimp_anaphor_number_agreement] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:38:17,225 WARNING  [task.py:811] [Task: blimp_anaphor_number_agreement] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb0d0899ef04056a95dbac5af37b5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/41.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d0a5efddcd4009b81e640493f709a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:38:20,586 WARNING  [task.py:799] [Task: blimp_anaphor_gender_agreement] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:38:20,587 WARNING  [task.py:811] [Task: blimp_anaphor_gender_agreement] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfa6144d7914d2d80ec2e0aa2231b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/39.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbb56efd98c4b29832baeaf4aa9ab91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:38:23,837 WARNING  [task.py:799] [Task: blimp_adjunct_island] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:16:38:23,838 WARNING  [task.py:811] [Task: blimp_adjunct_island] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a233f191f2dc4e669f038aca44d10661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/62.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5d20c4df7b4746b1aaeae3e826c9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18:16:38:26,763 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_adjunct_island in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,764 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_anaphor_gender_agreement in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,764 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_anaphor_number_agreement in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,765 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_animate_subject_passive in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,765 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_animate_subject_trans in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,766 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_causative in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,767 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_complex_NP_island in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,767 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_coordinate_structure_constraint_complex_left_branch in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,768 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_coordinate_structure_constraint_object_extraction in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,768 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,769 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,771 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_irregular_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,772 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_irregular_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,773 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_with_adj_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,773 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_with_adj_irregular_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,774 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_with_adj_irregular_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,775 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_with_adjective_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,775 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_distractor_agreement_relational_noun in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,776 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_distractor_agreement_relative_clause in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,776 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_drop_argument in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,777 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_ellipsis_n_bar_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,777 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_ellipsis_n_bar_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,778 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_existential_there_object_raising in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,779 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_existential_there_quantifiers_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,779 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_existential_there_quantifiers_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,780 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_existential_there_subject_raising in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,783 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_expletive_it_object_raising in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,783 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_inchoative in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,784 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_intransitive in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,784 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_irregular_past_participle_adjectives in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,785 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_irregular_past_participle_verbs in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,786 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_irregular_plural_subject_verb_agreement_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,786 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_irregular_plural_subject_verb_agreement_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,787 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_left_branch_island_echo_question in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,789 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_left_branch_island_simple_question in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,790 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_matrix_question_npi_licensor_present in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,790 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_npi_present_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,791 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_npi_present_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,791 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_only_npi_licensor_present in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,792 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_only_npi_scope in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,793 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_passive_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,793 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_passive_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,794 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_principle_A_c_command in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,794 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_principle_A_case_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,795 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_principle_A_case_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,795 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_principle_A_domain_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,796 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_principle_A_domain_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,797 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_principle_A_domain_3 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,797 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_principle_A_reconstruction in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,798 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_regular_plural_subject_verb_agreement_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,798 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_regular_plural_subject_verb_agreement_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,799 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_sentential_negation_npi_licensor_present in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,802 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_sentential_negation_npi_scope in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,803 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_sentential_subject_island in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,804 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_superlative_quantifiers_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,804 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_superlative_quantifiers_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,805 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_tough_vs_raising_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,805 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_tough_vs_raising_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,806 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_transitive in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,807 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_island in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,808 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_questions_object_gap in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,809 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_questions_subject_gap in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,809 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_questions_subject_gap_long_distance in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,810 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_vs_that_no_gap in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,811 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_vs_that_no_gap_long_distance in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,814 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_vs_that_with_gap in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,814 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_vs_that_with_gap_long_distance in its config. Manual configuration will be ignored.\n",
      "2024-11-18:16:38:26,815 WARNING  [evaluator.py:270] Overwriting default num_fewshot of lambada_standard from None to 0\n",
      "2024-11-18:16:38:26,815 WARNING  [evaluator.py:270] Overwriting default num_fewshot of lambada_openai from None to 0\n",
      "2024-11-18:16:38:26,816 WARNING  [evaluator.py:270] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-11-18:16:38:26,817 WARNING  [evaluator.py:270] Overwriting default num_fewshot of winogrande from None to 0\n",
      "2024-11-18:16:38:26,817 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
      "2024-11-18:16:38:26,819 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
      "2024-11-18:16:38:26,820 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
      "2024-11-18:16:38:26,820 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
      "2024-11-18:16:38:26,821 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
      "2024-11-18:16:38:26,822 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
      "2024-11-18:16:38:26,822 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
      "2024-11-18:16:38:26,823 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
      "2024-11-18:16:38:26,824 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
      "2024-11-18:16:38:26,826 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
      "2024-11-18:16:38:26,826 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
      "2024-11-18:16:38:26,827 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
      "2024-11-18:16:38:26,828 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
      "2024-11-18:16:38:26,828 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
      "2024-11-18:16:38:26,829 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
      "2024-11-18:16:38:26,829 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
      "2024-11-18:16:38:26,830 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
      "2024-11-18:16:38:26,831 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
      "2024-11-18:16:38:26,831 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
      "2024-11-18:16:38:26,832 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
      "2024-11-18:16:38:26,833 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
      "2024-11-18:16:38:26,836 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
      "2024-11-18:16:38:26,836 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
      "2024-11-18:16:38:26,837 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
      "2024-11-18:16:38:26,838 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_management from None to 0\n",
      "2024-11-18:16:38:26,838 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
      "2024-11-18:16:38:26,839 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
      "2024-11-18:16:38:26,840 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
      "2024-11-18:16:38:26,840 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
      "2024-11-18:16:38:26,842 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
      "2024-11-18:16:38:26,843 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
      "2024-11-18:16:38:26,844 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
      "2024-11-18:16:38:26,844 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
      "2024-11-18:16:38:26,845 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
      "2024-11-18:16:38:26,846 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
      "2024-11-18:16:38:26,846 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
      "2024-11-18:16:38:26,847 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
      "2024-11-18:16:38:26,847 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
      "2024-11-18:16:38:26,848 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
      "2024-11-18:16:38:26,849 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
      "2024-11-18:16:38:26,849 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
      "2024-11-18:16:38:26,850 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
      "2024-11-18:16:38:26,853 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
      "2024-11-18:16:38:26,853 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
      "2024-11-18:16:38:26,854 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
      "2024-11-18:16:38:26,855 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
      "2024-11-18:16:38:26,855 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
      "2024-11-18:16:38:26,856 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
      "2024-11-18:16:38:26,856 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
      "2024-11-18:16:38:26,857 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
      "2024-11-18:16:38:26,858 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
      "2024-11-18:16:38:26,858 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
      "2024-11-18:16:38:26,859 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
      "2024-11-18:16:38:26,860 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
      "2024-11-18:16:38:26,860 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
      "2024-11-18:16:38:26,861 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
      "2024-11-18:16:38:26,861 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
      "2024-11-18:16:38:26,862 WARNING  [evaluator.py:270] Overwriting default num_fewshot of arc_challenge from None to 0\n",
      "2024-11-18:16:38:26,908 INFO     [task.py:415] Building contexts for blimp_adjunct_island on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 876.19it/s]\n",
      "2024-11-18:16:38:28,242 INFO     [task.py:415] Building contexts for blimp_anaphor_gender_agreement on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 866.66it/s]\n",
      "2024-11-18:16:38:29,576 INFO     [task.py:415] Building contexts for blimp_anaphor_number_agreement on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 897.16it/s]\n",
      "2024-11-18:16:38:30,873 INFO     [task.py:415] Building contexts for blimp_animate_subject_passive on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 878.54it/s]\n",
      "2024-11-18:16:38:32,197 INFO     [task.py:415] Building contexts for blimp_animate_subject_trans on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 875.06it/s]\n",
      "2024-11-18:16:38:33,520 INFO     [task.py:415] Building contexts for blimp_causative on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 869.99it/s]\n",
      "2024-11-18:16:38:34,848 INFO     [task.py:415] Building contexts for blimp_complex_NP_island on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 872.74it/s]\n",
      "2024-11-18:16:38:36,180 INFO     [task.py:415] Building contexts for blimp_coordinate_structure_constraint_complex_left_branch on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 913.64it/s]\n",
      "2024-11-18:16:38:37,449 INFO     [task.py:415] Building contexts for blimp_coordinate_structure_constraint_object_extraction on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 899.14it/s]\n",
      "2024-11-18:16:38:38,742 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 888.64it/s]\n",
      "2024-11-18:16:38:40,070 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 846.45it/s]\n",
      "2024-11-18:16:38:41,435 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_irregular_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 923.56it/s]\n",
      "2024-11-18:16:38:42,690 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_irregular_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 904.95it/s]\n",
      "2024-11-18:16:38:44,020 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_with_adj_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 868.37it/s]\n",
      "2024-11-18:16:38:45,362 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_with_adj_irregular_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 875.04it/s]\n",
      "2024-11-18:16:38:46,695 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_with_adj_irregular_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 878.36it/s]\n",
      "2024-11-18:16:38:48,021 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_with_adjective_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 604.36it/s]\n",
      "2024-11-18:16:38:49,897 INFO     [task.py:415] Building contexts for blimp_distractor_agreement_relational_noun on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 853.45it/s]\n",
      "2024-11-18:16:38:51,257 INFO     [task.py:415] Building contexts for blimp_distractor_agreement_relative_clause on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 832.35it/s]\n",
      "2024-11-18:16:38:52,661 INFO     [task.py:415] Building contexts for blimp_drop_argument on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 924.16it/s]\n",
      "2024-11-18:16:38:53,966 INFO     [task.py:415] Building contexts for blimp_ellipsis_n_bar_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 920.37it/s]\n",
      "2024-11-18:16:38:55,232 INFO     [task.py:415] Building contexts for blimp_ellipsis_n_bar_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 901.55it/s]\n",
      "2024-11-18:16:38:56,517 INFO     [task.py:415] Building contexts for blimp_existential_there_object_raising on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 877.84it/s]\n",
      "2024-11-18:16:38:57,841 INFO     [task.py:415] Building contexts for blimp_existential_there_quantifiers_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 873.38it/s]\n",
      "2024-11-18:16:38:59,169 INFO     [task.py:415] Building contexts for blimp_existential_there_quantifiers_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 923.16it/s]\n",
      "2024-11-18:16:39:00,440 INFO     [task.py:415] Building contexts for blimp_existential_there_subject_raising on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 927.05it/s]\n",
      "2024-11-18:16:39:01,691 INFO     [task.py:415] Building contexts for blimp_expletive_it_object_raising on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 833.80it/s]\n",
      "2024-11-18:16:39:03,067 INFO     [task.py:415] Building contexts for blimp_inchoative on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 929.07it/s]\n",
      "2024-11-18:16:39:04,315 INFO     [task.py:415] Building contexts for blimp_intransitive on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 902.08it/s]\n",
      "2024-11-18:16:39:05,595 INFO     [task.py:415] Building contexts for blimp_irregular_past_participle_adjectives on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 898.19it/s]\n",
      "2024-11-18:16:39:06,894 INFO     [task.py:415] Building contexts for blimp_irregular_past_participle_verbs on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 859.86it/s]\n",
      "2024-11-18:16:39:08,232 INFO     [task.py:415] Building contexts for blimp_irregular_plural_subject_verb_agreement_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 885.40it/s]\n",
      "2024-11-18:16:39:09,541 INFO     [task.py:415] Building contexts for blimp_irregular_plural_subject_verb_agreement_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 889.60it/s]\n",
      "2024-11-18:16:39:10,858 INFO     [task.py:415] Building contexts for blimp_left_branch_island_echo_question on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 929.60it/s]\n",
      "2024-11-18:16:39:12,107 INFO     [task.py:415] Building contexts for blimp_left_branch_island_simple_question on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 873.71it/s]\n",
      "2024-11-18:16:39:13,453 INFO     [task.py:415] Building contexts for blimp_matrix_question_npi_licensor_present on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 895.94it/s]\n",
      "2024-11-18:16:39:14,758 INFO     [task.py:415] Building contexts for blimp_npi_present_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 912.48it/s]\n",
      "2024-11-18:16:39:16,039 INFO     [task.py:415] Building contexts for blimp_npi_present_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 907.41it/s]\n",
      "2024-11-18:16:39:17,317 INFO     [task.py:415] Building contexts for blimp_only_npi_licensor_present on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 901.69it/s]\n",
      "2024-11-18:16:39:18,608 INFO     [task.py:415] Building contexts for blimp_only_npi_scope on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 917.43it/s]\n",
      "2024-11-18:16:39:19,875 INFO     [task.py:415] Building contexts for blimp_passive_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 920.89it/s]\n",
      "2024-11-18:16:39:21,167 INFO     [task.py:415] Building contexts for blimp_passive_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 908.18it/s]\n",
      "2024-11-18:16:39:22,442 INFO     [task.py:415] Building contexts for blimp_principle_A_c_command on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 883.75it/s]\n",
      "2024-11-18:16:39:23,776 INFO     [task.py:415] Building contexts for blimp_principle_A_case_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 860.84it/s]\n",
      "2024-11-18:16:39:25,130 INFO     [task.py:415] Building contexts for blimp_principle_A_case_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 911.72it/s]\n",
      "2024-11-18:16:39:26,411 INFO     [task.py:415] Building contexts for blimp_principle_A_domain_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 899.53it/s]\n",
      "2024-11-18:16:39:27,702 INFO     [task.py:415] Building contexts for blimp_principle_A_domain_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 627.67it/s]\n",
      "2024-11-18:16:39:29,481 INFO     [task.py:415] Building contexts for blimp_principle_A_domain_3 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 857.39it/s]\n",
      "2024-11-18:16:39:30,828 INFO     [task.py:415] Building contexts for blimp_principle_A_reconstruction on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 834.24it/s]\n",
      "2024-11-18:16:39:32,253 INFO     [task.py:415] Building contexts for blimp_regular_plural_subject_verb_agreement_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 876.11it/s]\n",
      "2024-11-18:16:39:33,577 INFO     [task.py:415] Building contexts for blimp_regular_plural_subject_verb_agreement_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 864.86it/s]\n",
      "2024-11-18:16:39:34,920 INFO     [task.py:415] Building contexts for blimp_sentential_negation_npi_licensor_present on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 906.77it/s]\n",
      "2024-11-18:16:39:36,197 INFO     [task.py:415] Building contexts for blimp_sentential_negation_npi_scope on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 902.28it/s]\n",
      "2024-11-18:16:39:37,517 INFO     [task.py:415] Building contexts for blimp_sentential_subject_island on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 870.42it/s]\n",
      "2024-11-18:16:39:38,847 INFO     [task.py:415] Building contexts for blimp_superlative_quantifiers_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 916.96it/s]\n",
      "2024-11-18:16:39:40,141 INFO     [task.py:415] Building contexts for blimp_superlative_quantifiers_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 898.71it/s]\n",
      "2024-11-18:16:39:41,430 INFO     [task.py:415] Building contexts for blimp_tough_vs_raising_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 851.90it/s]\n",
      "2024-11-18:16:39:42,791 INFO     [task.py:415] Building contexts for blimp_tough_vs_raising_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 908.72it/s]\n",
      "2024-11-18:16:39:44,072 INFO     [task.py:415] Building contexts for blimp_transitive on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 917.28it/s]\n",
      "2024-11-18:16:39:45,349 INFO     [task.py:415] Building contexts for blimp_wh_island on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 902.87it/s]\n",
      "2024-11-18:16:39:46,630 INFO     [task.py:415] Building contexts for blimp_wh_questions_object_gap on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 907.55it/s]\n",
      "2024-11-18:16:39:47,990 INFO     [task.py:415] Building contexts for blimp_wh_questions_subject_gap on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 919.91it/s]\n",
      "2024-11-18:16:39:49,253 INFO     [task.py:415] Building contexts for blimp_wh_questions_subject_gap_long_distance on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 922.40it/s]\n",
      "2024-11-18:16:39:50,513 INFO     [task.py:415] Building contexts for blimp_wh_vs_that_no_gap on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 926.32it/s]\n",
      "2024-11-18:16:39:51,765 INFO     [task.py:415] Building contexts for blimp_wh_vs_that_no_gap_long_distance on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 879.53it/s]\n",
      "2024-11-18:16:39:53,100 INFO     [task.py:415] Building contexts for blimp_wh_vs_that_with_gap on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 910.68it/s]\n",
      "2024-11-18:16:39:54,372 INFO     [task.py:415] Building contexts for blimp_wh_vs_that_with_gap_long_distance on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 885.65it/s]\n",
      "2024-11-18:16:39:55,685 INFO     [task.py:415] Building contexts for lambada_standard on rank 0...\n",
      "100%|██████████| 5153/5153 [00:14<00:00, 366.02it/s]\n",
      "2024-11-18:16:40:10,065 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...\n",
      "100%|██████████| 5153/5153 [00:13<00:00, 373.45it/s]\n",
      "2024-11-18:16:40:24,101 INFO     [task.py:415] Building contexts for hellaswag on rank 0...\n",
      "100%|██████████| 10042/10042 [00:06<00:00, 1574.12it/s]\n",
      "2024-11-18:16:40:33,043 INFO     [task.py:415] Building contexts for winogrande on rank 0...\n",
      "100%|██████████| 1267/1267 [00:00<00:00, 52160.18it/s]\n",
      "2024-11-18:16:40:33,178 INFO     [task.py:415] Building contexts for mmlu_machine_learning on rank 0...\n",
      "100%|██████████| 112/112 [00:00<00:00, 425.09it/s]\n",
      "2024-11-18:16:40:33,457 INFO     [task.py:415] Building contexts for mmlu_astronomy on rank 0...\n",
      "100%|██████████| 152/152 [00:00<00:00, 428.09it/s]\n",
      "2024-11-18:16:40:33,832 INFO     [task.py:415] Building contexts for mmlu_college_mathematics on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 428.43it/s]\n",
      "2024-11-18:16:40:34,080 INFO     [task.py:415] Building contexts for mmlu_high_school_physics on rank 0...\n",
      "100%|██████████| 151/151 [00:00<00:00, 425.07it/s]\n",
      "2024-11-18:16:40:34,455 INFO     [task.py:415] Building contexts for mmlu_high_school_biology on rank 0...\n",
      "100%|██████████| 310/310 [00:00<00:00, 434.37it/s]\n",
      "2024-11-18:16:40:35,205 INFO     [task.py:415] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
      "100%|██████████| 270/270 [00:00<00:00, 434.85it/s]\n",
      "2024-11-18:16:40:35,858 INFO     [task.py:415] Building contexts for mmlu_college_computer_science on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 373.17it/s]\n",
      "2024-11-18:16:40:36,142 INFO     [task.py:415] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
      "100%|██████████| 378/378 [00:00<00:00, 421.20it/s]\n",
      "2024-11-18:16:40:37,093 INFO     [task.py:415] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
      "100%|██████████| 203/203 [00:00<00:00, 418.16it/s]\n",
      "2024-11-18:16:40:37,605 INFO     [task.py:415] Building contexts for mmlu_conceptual_physics on rank 0...\n",
      "100%|██████████| 235/235 [00:00<00:00, 415.02it/s]\n",
      "2024-11-18:16:40:38,200 INFO     [task.py:415] Building contexts for mmlu_computer_security on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 429.10it/s]\n",
      "2024-11-18:16:40:38,447 INFO     [task.py:415] Building contexts for mmlu_electrical_engineering on rank 0...\n",
      "100%|██████████| 145/145 [00:00<00:00, 432.64it/s]\n",
      "2024-11-18:16:40:38,801 INFO     [task.py:415] Building contexts for mmlu_anatomy on rank 0...\n",
      "100%|██████████| 135/135 [00:00<00:00, 432.81it/s]\n",
      "2024-11-18:16:40:39,131 INFO     [task.py:415] Building contexts for mmlu_college_chemistry on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 420.15it/s]\n",
      "2024-11-18:16:40:39,383 INFO     [task.py:415] Building contexts for mmlu_college_physics on rank 0...\n",
      "100%|██████████| 102/102 [00:00<00:00, 417.14it/s]\n",
      "2024-11-18:16:40:39,642 INFO     [task.py:415] Building contexts for mmlu_abstract_algebra on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 428.80it/s]\n",
      "2024-11-18:16:40:39,890 INFO     [task.py:415] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 422.49it/s]\n",
      "2024-11-18:16:40:40,141 INFO     [task.py:415] Building contexts for mmlu_college_biology on rank 0...\n",
      "100%|██████████| 144/144 [00:00<00:00, 427.11it/s]\n",
      "2024-11-18:16:40:40,497 INFO     [task.py:415] Building contexts for mmlu_high_school_statistics on rank 0...\n",
      "100%|██████████| 216/216 [00:00<00:00, 398.44it/s]\n",
      "2024-11-18:16:40:41,069 INFO     [task.py:415] Building contexts for mmlu_global_facts on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 370.83it/s]\n",
      "2024-11-18:16:40:41,353 INFO     [task.py:415] Building contexts for mmlu_marketing on rank 0...\n",
      "100%|██████████| 234/234 [00:00<00:00, 402.46it/s]\n",
      "2024-11-18:16:40:41,968 INFO     [task.py:415] Building contexts for mmlu_nutrition on rank 0...\n",
      "100%|██████████| 306/306 [00:00<00:00, 423.79it/s]\n",
      "2024-11-18:16:40:42,730 INFO     [task.py:415] Building contexts for mmlu_college_medicine on rank 0...\n",
      "100%|██████████| 173/173 [00:00<00:00, 417.91it/s]\n",
      "2024-11-18:16:40:43,167 INFO     [task.py:415] Building contexts for mmlu_business_ethics on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 423.85it/s]\n",
      "2024-11-18:16:40:43,419 INFO     [task.py:415] Building contexts for mmlu_management on rank 0...\n",
      "100%|██████████| 103/103 [00:00<00:00, 425.21it/s]\n",
      "2024-11-18:16:40:43,678 INFO     [task.py:415] Building contexts for mmlu_virology on rank 0...\n",
      "100%|██████████| 166/166 [00:00<00:00, 430.14it/s]\n",
      "2024-11-18:16:40:44,086 INFO     [task.py:415] Building contexts for mmlu_human_aging on rank 0...\n",
      "100%|██████████| 223/223 [00:00<00:00, 397.36it/s]\n",
      "2024-11-18:16:40:44,674 INFO     [task.py:415] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
      "100%|██████████| 265/265 [00:00<00:00, 423.22it/s]\n",
      "2024-11-18:16:40:45,333 INFO     [task.py:415] Building contexts for mmlu_medical_genetics on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 424.59it/s]\n",
      "2024-11-18:16:40:45,583 INFO     [task.py:415] Building contexts for mmlu_professional_medicine on rank 0...\n",
      "100%|██████████| 272/272 [00:00<00:00, 426.43it/s]\n",
      "2024-11-18:16:40:46,255 INFO     [task.py:415] Building contexts for mmlu_professional_accounting on rank 0...\n",
      "100%|██████████| 282/282 [00:00<00:00, 405.74it/s]\n",
      "2024-11-18:16:40:46,984 INFO     [task.py:415] Building contexts for mmlu_miscellaneous on rank 0...\n",
      "100%|██████████| 783/783 [00:01<00:00, 435.71it/s]\n",
      "2024-11-18:16:40:48,864 INFO     [task.py:415] Building contexts for mmlu_econometrics on rank 0...\n",
      "100%|██████████| 114/114 [00:00<00:00, 365.98it/s]\n",
      "2024-11-18:16:40:49,192 INFO     [task.py:415] Building contexts for mmlu_professional_psychology on rank 0...\n",
      "100%|██████████| 612/612 [00:01<00:00, 426.11it/s]\n",
      "2024-11-18:16:40:50,704 INFO     [task.py:415] Building contexts for mmlu_high_school_psychology on rank 0...\n",
      "100%|██████████| 545/545 [00:01<00:00, 421.93it/s]\n",
      "2024-11-18:16:40:52,058 INFO     [task.py:415] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
      "100%|██████████| 193/193 [00:00<00:00, 426.03it/s]\n",
      "2024-11-18:16:40:52,535 INFO     [task.py:415] Building contexts for mmlu_sociology on rank 0...\n",
      "100%|██████████| 201/201 [00:00<00:00, 406.04it/s]\n",
      "2024-11-18:16:40:53,055 INFO     [task.py:415] Building contexts for mmlu_human_sexuality on rank 0...\n",
      "100%|██████████| 131/131 [00:00<00:00, 409.91it/s]\n",
      "2024-11-18:16:40:53,391 INFO     [task.py:415] Building contexts for mmlu_high_school_geography on rank 0...\n",
      "100%|██████████| 198/198 [00:00<00:00, 417.75it/s]\n",
      "2024-11-18:16:40:53,890 INFO     [task.py:415] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
      "100%|██████████| 390/390 [00:00<00:00, 418.33it/s]\n",
      "2024-11-18:16:40:54,869 INFO     [task.py:415] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
      "100%|██████████| 238/238 [00:00<00:00, 426.49it/s]\n",
      "2024-11-18:16:40:55,458 INFO     [task.py:415] Building contexts for mmlu_public_relations on rank 0...\n",
      "100%|██████████| 110/110 [00:00<00:00, 432.39it/s]\n",
      "2024-11-18:16:40:55,728 INFO     [task.py:415] Building contexts for mmlu_security_studies on rank 0...\n",
      "100%|██████████| 245/245 [00:00<00:00, 415.60it/s]\n",
      "2024-11-18:16:40:56,348 INFO     [task.py:415] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 362.33it/s]\n",
      "2024-11-18:16:40:56,639 INFO     [task.py:415] Building contexts for mmlu_international_law on rank 0...\n",
      "100%|██████████| 121/121 [00:00<00:00, 377.21it/s]\n",
      "2024-11-18:16:40:56,981 INFO     [task.py:415] Building contexts for mmlu_high_school_european_history on rank 0...\n",
      "100%|██████████| 165/165 [00:00<00:00, 426.75it/s]\n",
      "2024-11-18:16:40:57,390 INFO     [task.py:415] Building contexts for mmlu_philosophy on rank 0...\n",
      "100%|██████████| 311/311 [00:00<00:00, 416.71it/s]\n",
      "2024-11-18:16:40:58,174 INFO     [task.py:415] Building contexts for mmlu_moral_scenarios on rank 0...\n",
      "100%|██████████| 895/895 [00:02<00:00, 407.73it/s]\n",
      "2024-11-18:16:41:00,484 INFO     [task.py:415] Building contexts for mmlu_jurisprudence on rank 0...\n",
      "100%|██████████| 108/108 [00:00<00:00, 413.23it/s]\n",
      "2024-11-18:16:41:00,761 INFO     [task.py:415] Building contexts for mmlu_formal_logic on rank 0...\n",
      "100%|██████████| 126/126 [00:00<00:00, 396.54it/s]\n",
      "2024-11-18:16:41:01,099 INFO     [task.py:415] Building contexts for mmlu_world_religions on rank 0...\n",
      "100%|██████████| 171/171 [00:00<00:00, 425.48it/s]\n",
      "2024-11-18:16:41:01,523 INFO     [task.py:415] Building contexts for mmlu_prehistory on rank 0...\n",
      "100%|██████████| 324/324 [00:00<00:00, 393.55it/s]\n",
      "2024-11-18:16:41:02,384 INFO     [task.py:415] Building contexts for mmlu_high_school_us_history on rank 0...\n",
      "100%|██████████| 204/204 [00:00<00:00, 413.83it/s]\n",
      "2024-11-18:16:41:02,905 INFO     [task.py:415] Building contexts for mmlu_moral_disputes on rank 0...\n",
      "100%|██████████| 346/346 [00:00<00:00, 425.60it/s]\n",
      "2024-11-18:16:41:03,757 INFO     [task.py:415] Building contexts for mmlu_logical_fallacies on rank 0...\n",
      "100%|██████████| 163/163 [00:00<00:00, 425.83it/s]\n",
      "2024-11-18:16:41:04,161 INFO     [task.py:415] Building contexts for mmlu_high_school_world_history on rank 0...\n",
      "100%|██████████| 237/237 [00:00<00:00, 415.33it/s]\n",
      "2024-11-18:16:41:04,764 INFO     [task.py:415] Building contexts for mmlu_professional_law on rank 0...\n",
      "100%|██████████| 1534/1534 [00:04<00:00, 357.10it/s]\n",
      "2024-11-18:16:41:09,236 INFO     [task.py:415] Building contexts for arc_challenge on rank 0...\n",
      "100%|██████████| 1172/1172 [00:01<00:00, 766.84it/s]\n",
      "2024-11-18:16:41:10,933 INFO     [evaluator.py:489] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████████| 247863/247863 [1:17:03<00:00, 53.61it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrapping for stddev: perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.34it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrapping for stddev: perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.44it/s]\n",
      "2024-11-18:18:02:39,996 WARNING  [huggingface.py:1353] Failed to get model SHA for GPTNeoXForCausalLM(\n",
      "  (gpt_neox): GPTNeoXModel(\n",
      "    (embed_in): Embedding(50304, 768)\n",
      "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x GPTNeoXLayer(\n",
      "        (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (attention): GPTNeoXSdpaAttention(\n",
      "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "          (query_key_value): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): GPTNeoXMLP(\n",
      "          (dense_h_to_4h): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (dense_4h_to_h): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELUActivation()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "  )\n",
      "  (embed_out): Linear(in_features=768, out_features=50304, bias=False)\n",
      ") at revision main. Error: Repo id must be a string, not <class 'transformers.models.gpt_neox.modeling_gpt_neox.GPTNeoXForCausalLM'>: 'GPTNeoXForCausalLM(\n",
      "  (gpt_neox): GPTNeoXModel(\n",
      "    (embed_in): Embedding(50304, 768)\n",
      "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x GPTNeoXLayer(\n",
      "        (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (attention): GPTNeoXSdpaAttention(\n",
      "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "          (query_key_value): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): GPTNeoXMLP(\n",
      "          (dense_h_to_4h): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (dense_4h_to_h): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELUActivation()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "  )\n",
      "  (embed_out): Linear(in_features=768, out_features=50304, bias=False)\n",
      ")'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                           Tasks                            |Version|Filter|n-shot|  Metric  |   | Value  |   |Stderr|\n",
      "|------------------------------------------------------------|------:|------|-----:|----------|---|-------:|---|-----:|\n",
      "|arc_challenge                                               |      1|none  |     0|acc       |↑  |  0.1997|±  |0.0117|\n",
      "|                                                            |       |none  |     0|acc_norm  |↑  |  0.2398|±  |0.0125|\n",
      "|blimp                                                       |      2|none  |      |acc       |↑  |  0.7294|±  |0.0015|\n",
      "| - blimp_adjunct_island                                     |      1|none  |     0|acc       |↑  |  0.8150|±  |0.0123|\n",
      "| - blimp_anaphor_gender_agreement                           |      1|none  |     0|acc       |↑  |  0.9640|±  |0.0059|\n",
      "| - blimp_anaphor_number_agreement                           |      1|none  |     0|acc       |↑  |  0.9810|±  |0.0043|\n",
      "| - blimp_animate_subject_passive                            |      1|none  |     0|acc       |↑  |  0.7870|±  |0.0130|\n",
      "| - blimp_animate_subject_trans                              |      1|none  |     0|acc       |↑  |  0.7310|±  |0.0140|\n",
      "| - blimp_causative                                          |      1|none  |     0|acc       |↑  |  0.7060|±  |0.0144|\n",
      "| - blimp_complex_NP_island                                  |      1|none  |     0|acc       |↑  |  0.5360|±  |0.0158|\n",
      "| - blimp_coordinate_structure_constraint_complex_left_branch|      1|none  |     0|acc       |↑  |  0.3500|±  |0.0151|\n",
      "| - blimp_coordinate_structure_constraint_object_extraction  |      1|none  |     0|acc       |↑  |  0.7390|±  |0.0139|\n",
      "| - blimp_determiner_noun_agreement_1                        |      1|none  |     0|acc       |↑  |  0.9670|±  |0.0057|\n",
      "| - blimp_determiner_noun_agreement_2                        |      1|none  |     0|acc       |↑  |  0.9480|±  |0.0070|\n",
      "| - blimp_determiner_noun_agreement_irregular_1              |      1|none  |     0|acc       |↑  |  0.8330|±  |0.0118|\n",
      "| - blimp_determiner_noun_agreement_irregular_2              |      1|none  |     0|acc       |↑  |  0.8510|±  |0.0113|\n",
      "| - blimp_determiner_noun_agreement_with_adj_2               |      1|none  |     0|acc       |↑  |  0.8850|±  |0.0101|\n",
      "| - blimp_determiner_noun_agreement_with_adj_irregular_1     |      1|none  |     0|acc       |↑  |  0.8050|±  |0.0125|\n",
      "| - blimp_determiner_noun_agreement_with_adj_irregular_2     |      1|none  |     0|acc       |↑  |  0.8390|±  |0.0116|\n",
      "| - blimp_determiner_noun_agreement_with_adjective_1         |      1|none  |     0|acc       |↑  |  0.9170|±  |0.0087|\n",
      "| - blimp_distractor_agreement_relational_noun               |      1|none  |     0|acc       |↑  |  0.7400|±  |0.0139|\n",
      "| - blimp_distractor_agreement_relative_clause               |      1|none  |     0|acc       |↑  |  0.5460|±  |0.0158|\n",
      "| - blimp_drop_argument                                      |      1|none  |     0|acc       |↑  |  0.6880|±  |0.0147|\n",
      "| - blimp_ellipsis_n_bar_1                                   |      1|none  |     0|acc       |↑  |  0.6770|±  |0.0148|\n",
      "| - blimp_ellipsis_n_bar_2                                   |      1|none  |     0|acc       |↑  |  0.9250|±  |0.0083|\n",
      "| - blimp_existential_there_object_raising                   |      1|none  |     0|acc       |↑  |  0.8740|±  |0.0105|\n",
      "| - blimp_existential_there_quantifiers_1                    |      1|none  |     0|acc       |↑  |  0.9700|±  |0.0054|\n",
      "| - blimp_existential_there_quantifiers_2                    |      1|none  |     0|acc       |↑  |  0.1860|±  |0.0123|\n",
      "| - blimp_existential_there_subject_raising                  |      1|none  |     0|acc       |↑  |  0.8090|±  |0.0124|\n",
      "| - blimp_expletive_it_object_raising                        |      1|none  |     0|acc       |↑  |  0.7800|±  |0.0131|\n",
      "| - blimp_inchoative                                         |      1|none  |     0|acc       |↑  |  0.5650|±  |0.0157|\n",
      "| - blimp_intransitive                                       |      1|none  |     0|acc       |↑  |  0.6870|±  |0.0147|\n",
      "| - blimp_irregular_past_participle_adjectives               |      1|none  |     0|acc       |↑  |  0.7060|±  |0.0144|\n",
      "| - blimp_irregular_past_participle_verbs                    |      1|none  |     0|acc       |↑  |  0.7900|±  |0.0129|\n",
      "| - blimp_irregular_plural_subject_verb_agreement_1          |      1|none  |     0|acc       |↑  |  0.8690|±  |0.0107|\n",
      "| - blimp_irregular_plural_subject_verb_agreement_2          |      1|none  |     0|acc       |↑  |  0.7530|±  |0.0136|\n",
      "| - blimp_left_branch_island_echo_question                   |      1|none  |     0|acc       |↑  |  0.3540|±  |0.0151|\n",
      "| - blimp_left_branch_island_simple_question                 |      1|none  |     0|acc       |↑  |  0.2840|±  |0.0143|\n",
      "| - blimp_matrix_question_npi_licensor_present               |      1|none  |     0|acc       |↑  |  0.2440|±  |0.0136|\n",
      "| - blimp_npi_present_1                                      |      1|none  |     0|acc       |↑  |  0.6470|±  |0.0151|\n",
      "| - blimp_npi_present_2                                      |      1|none  |     0|acc       |↑  |  0.6300|±  |0.0153|\n",
      "| - blimp_only_npi_licensor_present                          |      1|none  |     0|acc       |↑  |  1.0000|±  |0.0000|\n",
      "| - blimp_only_npi_scope                                     |      1|none  |     0|acc       |↑  |  0.8510|±  |0.0113|\n",
      "| - blimp_passive_1                                          |      1|none  |     0|acc       |↑  |  0.8830|±  |0.0102|\n",
      "| - blimp_passive_2                                          |      1|none  |     0|acc       |↑  |  0.8660|±  |0.0108|\n",
      "| - blimp_principle_A_c_command                              |      1|none  |     0|acc       |↑  |  0.5160|±  |0.0158|\n",
      "| - blimp_principle_A_case_1                                 |      1|none  |     0|acc       |↑  |  1.0000|±  |0.0000|\n",
      "| - blimp_principle_A_case_2                                 |      1|none  |     0|acc       |↑  |  0.9450|±  |0.0072|\n",
      "| - blimp_principle_A_domain_1                               |      1|none  |     0|acc       |↑  |  0.9910|±  |0.0030|\n",
      "| - blimp_principle_A_domain_2                               |      1|none  |     0|acc       |↑  |  0.8200|±  |0.0122|\n",
      "| - blimp_principle_A_domain_3                               |      1|none  |     0|acc       |↑  |  0.5840|±  |0.0156|\n",
      "| - blimp_principle_A_reconstruction                         |      1|none  |     0|acc       |↑  |  0.1610|±  |0.0116|\n",
      "| - blimp_regular_plural_subject_verb_agreement_1            |      1|none  |     0|acc       |↑  |  0.8770|±  |0.0104|\n",
      "| - blimp_regular_plural_subject_verb_agreement_2            |      1|none  |     0|acc       |↑  |  0.8610|±  |0.0109|\n",
      "| - blimp_sentential_negation_npi_licensor_present           |      1|none  |     0|acc       |↑  |  0.9990|±  |0.0010|\n",
      "| - blimp_sentential_negation_npi_scope                      |      1|none  |     0|acc       |↑  |  0.6850|±  |0.0147|\n",
      "| - blimp_sentential_subject_island                          |      1|none  |     0|acc       |↑  |  0.3300|±  |0.0149|\n",
      "| - blimp_superlative_quantifiers_1                          |      1|none  |     0|acc       |↑  |  0.6370|±  |0.0152|\n",
      "| - blimp_superlative_quantifiers_2                          |      1|none  |     0|acc       |↑  |  0.7620|±  |0.0135|\n",
      "| - blimp_tough_vs_raising_1                                 |      1|none  |     0|acc       |↑  |  0.5340|±  |0.0158|\n",
      "| - blimp_tough_vs_raising_2                                 |      1|none  |     0|acc       |↑  |  0.8340|±  |0.0118|\n",
      "| - blimp_transitive                                         |      1|none  |     0|acc       |↑  |  0.8020|±  |0.0126|\n",
      "| - blimp_wh_island                                          |      1|none  |     0|acc       |↑  |  0.6700|±  |0.0149|\n",
      "| - blimp_wh_questions_object_gap                            |      1|none  |     0|acc       |↑  |  0.6840|±  |0.0147|\n",
      "| - blimp_wh_questions_subject_gap                           |      1|none  |     0|acc       |↑  |  0.8820|±  |0.0102|\n",
      "| - blimp_wh_questions_subject_gap_long_distance             |      1|none  |     0|acc       |↑  |  0.8260|±  |0.0120|\n",
      "| - blimp_wh_vs_that_no_gap                                  |      1|none  |     0|acc       |↑  |  0.9730|±  |0.0051|\n",
      "| - blimp_wh_vs_that_no_gap_long_distance                    |      1|none  |     0|acc       |↑  |  0.9700|±  |0.0054|\n",
      "| - blimp_wh_vs_that_with_gap                                |      1|none  |     0|acc       |↑  |  0.4010|±  |0.0155|\n",
      "| - blimp_wh_vs_that_with_gap_long_distance                  |      1|none  |     0|acc       |↑  |  0.1500|±  |0.0113|\n",
      "|hellaswag                                                   |      1|none  |     0|acc       |↑  |  0.2903|±  |0.0045|\n",
      "|                                                            |       |none  |     0|acc_norm  |↑  |  0.3135|±  |0.0046|\n",
      "|lambada_openai                                              |      1|none  |     0|acc       |↑  |  0.3691|±  |0.0067|\n",
      "|                                                            |       |none  |     0|perplexity|↓  | 31.2589|±  |1.1594|\n",
      "|lambada_standard                                            |      1|none  |     0|acc       |↑  |  0.2335|±  |0.0059|\n",
      "|                                                            |       |none  |     0|perplexity|↓  |172.7619|±  |7.7265|\n",
      "|mmlu                                                        |      2|none  |      |acc       |↑  |  0.2299|±  |0.0035|\n",
      "| - humanities                                               |      2|none  |      |acc       |↑  |  0.2417|±  |0.0062|\n",
      "|  - formal_logic                                            |      1|none  |     0|acc       |↑  |  0.2778|±  |0.0401|\n",
      "|  - high_school_european_history                            |      1|none  |     0|acc       |↑  |  0.2242|±  |0.0326|\n",
      "|  - high_school_us_history                                  |      1|none  |     0|acc       |↑  |  0.2500|±  |0.0304|\n",
      "|  - high_school_world_history                               |      1|none  |     0|acc       |↑  |  0.2700|±  |0.0289|\n",
      "|  - international_law                                       |      1|none  |     0|acc       |↑  |  0.2397|±  |0.0390|\n",
      "|  - jurisprudence                                           |      1|none  |     0|acc       |↑  |  0.2593|±  |0.0424|\n",
      "|  - logical_fallacies                                       |      1|none  |     0|acc       |↑  |  0.2209|±  |0.0326|\n",
      "|  - moral_disputes                                          |      1|none  |     0|acc       |↑  |  0.2486|±  |0.0233|\n",
      "|  - moral_scenarios                                         |      1|none  |     0|acc       |↑  |  0.2380|±  |0.0142|\n",
      "|  - philosophy                                              |      1|none  |     0|acc       |↑  |  0.1865|±  |0.0221|\n",
      "|  - prehistory                                              |      1|none  |     0|acc       |↑  |  0.2130|±  |0.0228|\n",
      "|  - professional_law                                        |      1|none  |     0|acc       |↑  |  0.2458|±  |0.0110|\n",
      "|  - world_religions                                         |      1|none  |     0|acc       |↑  |  0.3158|±  |0.0357|\n",
      "| - other                                                    |      2|none  |      |acc       |↑  |  0.2401|±  |0.0076|\n",
      "|  - business_ethics                                         |      1|none  |     0|acc       |↑  |  0.3000|±  |0.0461|\n",
      "|  - clinical_knowledge                                      |      1|none  |     0|acc       |↑  |  0.2151|±  |0.0253|\n",
      "|  - college_medicine                                        |      1|none  |     0|acc       |↑  |  0.2081|±  |0.0310|\n",
      "|  - global_facts                                            |      1|none  |     0|acc       |↑  |  0.1800|±  |0.0386|\n",
      "|  - human_aging                                             |      1|none  |     0|acc       |↑  |  0.3094|±  |0.0310|\n",
      "|  - management                                              |      1|none  |     0|acc       |↑  |  0.1748|±  |0.0376|\n",
      "|  - marketing                                               |      1|none  |     0|acc       |↑  |  0.2906|±  |0.0297|\n",
      "|  - medical_genetics                                        |      1|none  |     0|acc       |↑  |  0.3000|±  |0.0461|\n",
      "|  - miscellaneous                                           |      1|none  |     0|acc       |↑  |  0.2375|±  |0.0152|\n",
      "|  - nutrition                                               |      1|none  |     0|acc       |↑  |  0.2190|±  |0.0237|\n",
      "|  - professional_accounting                                 |      1|none  |     0|acc       |↑  |  0.2340|±  |0.0253|\n",
      "|  - professional_medicine                                   |      1|none  |     0|acc       |↑  |  0.1985|±  |0.0242|\n",
      "|  - virology                                                |      1|none  |     0|acc       |↑  |  0.2831|±  |0.0351|\n",
      "| - social sciences                                          |      2|none  |      |acc       |↑  |  0.2187|±  |0.0074|\n",
      "|  - econometrics                                            |      1|none  |     0|acc       |↑  |  0.2368|±  |0.0400|\n",
      "|  - high_school_geography                                   |      1|none  |     0|acc       |↑  |  0.1869|±  |0.0278|\n",
      "|  - high_school_government_and_politics                     |      1|none  |     0|acc       |↑  |  0.1969|±  |0.0287|\n",
      "|  - high_school_macroeconomics                              |      1|none  |     0|acc       |↑  |  0.2051|±  |0.0205|\n",
      "|  - high_school_microeconomics                              |      1|none  |     0|acc       |↑  |  0.2101|±  |0.0265|\n",
      "|  - high_school_psychology                                  |      1|none  |     0|acc       |↑  |  0.1927|±  |0.0169|\n",
      "|  - human_sexuality                                         |      1|none  |     0|acc       |↑  |  0.2595|±  |0.0384|\n",
      "|  - professional_psychology                                 |      1|none  |     0|acc       |↑  |  0.2516|±  |0.0176|\n",
      "|  - public_relations                                        |      1|none  |     0|acc       |↑  |  0.2182|±  |0.0396|\n",
      "|  - security_studies                                        |      1|none  |     0|acc       |↑  |  0.1878|±  |0.0250|\n",
      "|  - sociology                                               |      1|none  |     0|acc       |↑  |  0.2488|±  |0.0306|\n",
      "|  - us_foreign_policy                                       |      1|none  |     0|acc       |↑  |  0.2800|±  |0.0451|\n",
      "| - stem                                                     |      2|none  |      |acc       |↑  |  0.2131|±  |0.0073|\n",
      "|  - abstract_algebra                                        |      1|none  |     0|acc       |↑  |  0.2200|±  |0.0416|\n",
      "|  - anatomy                                                 |      1|none  |     0|acc       |↑  |  0.1926|±  |0.0341|\n",
      "|  - astronomy                                               |      1|none  |     0|acc       |↑  |  0.1776|±  |0.0311|\n",
      "|  - college_biology                                         |      1|none  |     0|acc       |↑  |  0.2639|±  |0.0369|\n",
      "|  - college_chemistry                                       |      1|none  |     0|acc       |↑  |  0.1900|±  |0.0394|\n",
      "|  - college_computer_science                                |      1|none  |     0|acc       |↑  |  0.2600|±  |0.0441|\n",
      "|  - college_mathematics                                     |      1|none  |     0|acc       |↑  |  0.2100|±  |0.0409|\n",
      "|  - college_physics                                         |      1|none  |     0|acc       |↑  |  0.2157|±  |0.0409|\n",
      "|  - computer_security                                       |      1|none  |     0|acc       |↑  |  0.2800|±  |0.0451|\n",
      "|  - conceptual_physics                                      |      1|none  |     0|acc       |↑  |  0.2596|±  |0.0287|\n",
      "|  - electrical_engineering                                  |      1|none  |     0|acc       |↑  |  0.2345|±  |0.0353|\n",
      "|  - elementary_mathematics                                  |      1|none  |     0|acc       |↑  |  0.2090|±  |0.0209|\n",
      "|  - high_school_biology                                     |      1|none  |     0|acc       |↑  |  0.1742|±  |0.0216|\n",
      "|  - high_school_chemistry                                   |      1|none  |     0|acc       |↑  |  0.1724|±  |0.0266|\n",
      "|  - high_school_computer_science                            |      1|none  |     0|acc       |↑  |  0.2600|±  |0.0441|\n",
      "|  - high_school_mathematics                                 |      1|none  |     0|acc       |↑  |  0.2074|±  |0.0247|\n",
      "|  - high_school_physics                                     |      1|none  |     0|acc       |↑  |  0.1987|±  |0.0326|\n",
      "|  - high_school_statistics                                  |      1|none  |     0|acc       |↑  |  0.1528|±  |0.0245|\n",
      "|  - machine_learning                                        |      1|none  |     0|acc       |↑  |  0.3125|±  |0.0440|\n",
      "|winogrande                                                  |      1|none  |     0|acc       |↑  |  0.4957|±  |0.0141|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluation - Pythia 160M Trained on Pile\n",
    "\n",
    "# Showcase uses Pythia: https://colab.research.google.com/github/EleutherAI/lm-evaluation-harness/blob/main/examples/lm-eval-overview.ipynb\n",
    "# Only genuine doc seems to be (a mess): https://github.com/EleutherAI/lm-evaluation-harness/tree/main/docs\n",
    "\n",
    "# Load model and tokenizer\n",
    "pythia_pile = AutoModelForCausalLM.from_pretrained(base_path / \"pythia160m_dedup_pile\", local_files_only=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_path / \"pythia160m_dedup_untrained\", use_fast=True, local_files_only=True)\n",
    "pythia_pile = pythia_pile.to(device)\n",
    "\n",
    "# From the HuggingFace Data Views (allenai/ai2_arc, cais/mmlu, allenai/winogrande, Rowan/hellaswag):\n",
    "# MMLU: {'answer': 1, 'choices': ['0', '4', '2', '6'], 'question': 'Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q.', 'subject': 'abstract_algebra'}\n",
    "# ARC-C: {'id': 'Mercury_7175875', 'question': 'An astronomer observes that a planet rotates faster after a meteorite impact. Which is the most likely effect of this increase in rotation?', 'choices': {'text': ['Planetary density will decrease.', 'Planetary years will become longer.', 'Planetary days will become shorter.', 'Planetary gravity will become stronger.'], 'label': ['A', 'B', 'C', 'D']}, 'answerKey': 'C'}\n",
    "# Winogrande: {'sentence': \"Ian volunteered to eat Dennis's menudo after already having a bowl because _ despised eating intestine.\", 'option1': 'Ian', 'option2': 'Dennis', 'answer': '2'} (answer content not contained in test set)\n",
    "# HellaSwag: {'ind': 14, 'activity_label': 'Wakeboarding', 'ctx_a': 'A man is being pulled on a water ski as he floats in the water casually.', 'ctx_b': 'he', 'ctx': 'A man is being pulled on a water ski as he floats in the water casually. he', 'endings': ['mounts the water ski and tears through the water at fast speeds.', 'goes over several speeds, trying to stay upright.', 'struggles a little bit as he talks about it.', 'is seated in a boat with three other people.'], 'source_id': 'activitynet~v_-5KAycAQlC4', 'split': 'test', 'split_type': 'indomain', 'label': ''}\n",
    "# Lambada (OAI): {'text': 'In my palm is a clear stone, and inside it is a small ivory statuette. A guardian angel.\\n\\n\"Figured if you\\'re going to be out at night getting hit by cars, you might as well have some backup.\"\\n\\nI look at him, feeling stunned. Like this is some sort of sign. But as I stare at Harlin, his mouth curved in a confident grin, I don\\'t care about signs'}\n",
    "# BLiMP: {'sentence_good': 'Who should Derek hug after shocking Richard?', 'sentence_bad': 'Who should Derek hug Richard after shocking?', 'field': 'syntax', 'linguistics_term': 'island_effects', 'UID': 'adjunct_island', 'simple_LM_method': true, 'one_prefix_method': false, 'two_prefix_method': false, 'lexically_identical': true, 'pair_id': 0}\n",
    " \n",
    "batch_size_hflm = 1\n",
    "\n",
    "# Found that in here of all things: https://github.com/pytorch/ao/blob/e2301e9dba91fa962d673fdc3b3f0002856a3ba7/torchao/_models/_eval.py#L17-L22\n",
    "# https://github.com/EleutherAI/lm-evaluation-harness/blob/main/lm_eval/models/huggingface.py\n",
    "pythia_pile_hflm = HFLM(pretrained=pythia_pile,\n",
    "                        tokenizer=tokenizer,\n",
    "                        batch_size=batch_size_hflm)\n",
    "\n",
    "# Thankfully both MMLU and ARC are available in the lm_eval.tasks module\n",
    "# https://github.com/EleutherAI/lm-evaluation-harness/blob/main/lm_eval/tasks/arc\n",
    "# https://github.com/EleutherAI/lm-evaluation-harness/tree/main/lm_eval/tasks/mmlu\n",
    "# Initially evaluator.evaluate looked promising, but I don't understand it and this works\n",
    "# Found simple_evaluate in https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md\n",
    "# Winogrande is in fact 'winogrande_xl', see https://github.com/EleutherAI/lm-evaluation-harness/blob/main/lm_eval/tasks/winogrande/default.yaml\n",
    "results = simple_evaluate(model=pythia_pile_hflm,\n",
    "                          tasks=[\"arc_challenge\", \"mmlu\", \"winogrande\", \"hellaswag\", \"lambada\", \"blimp\"], # I have no idea how to inject pre-downloaded datasets here, I gave up on that\n",
    "                          num_fewshot=0,  # Pythia paper stated they used zero-shot\n",
    "                          batch_size=batch_size_hflm,\n",
    "                          device=\"cuda\",\n",
    "                          limit=None)\n",
    "\n",
    "# Save for reference (for proof of table below)\n",
    "with open('02_eval_160M_pretrained.txt', 'w') as f:\n",
    "    f.write(str(results))\n",
    "\n",
    "# Manually saved this to 02_eval_160M_pretrained_table.txt\n",
    "# This was nicely documented. Not. https://raw.githubusercontent.com/pytorch/torchtune/main/recipes/eleuther_eval.py\n",
    "print(utils.make_table(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pro of this is that the processing is standardized and I know this works with Pythia models because the doc uses Pythia as the de-facto use case example\n",
    "    - However, with this implementation I have no idea what's actually going on under the hood\n",
    "    - Doesn't feel right, I'll read up on this and write more about it here. But the pipeline works\n",
    "- How do we know this benchmarking pipeline actually benchmarks correctly?\n",
    "    - Utilize the reported Pythia Benchmarks from the paper and compare\n",
    "\n",
    "![](./img/pythia_paper_dedup_benchmarks.png)\n",
    "\n",
    "I initially reported to benchmark only on ARC-Challenge and MMLU.<br>\n",
    "After reporting this, I quickly concluded that I wanted to use more benchmarks, specifically some of the ones mentioned in the Pythia paper to cross reference whether the evaluation pipeline itself is correct. Also, if that were to be the case, we would have a more information-rich benchmarking report. Who wouldn't want that?\n",
    "\n",
    "The overlapping confidence intervals suggest that the performances on WinoGrande and ARC-Challenge are consistent with the reported results.<br>\n",
    "This is narrowly not the case for Lambada (OpenAI).<br>\n",
    "Note that the benchmarking approach used here also reports larger `stderrs`.<br>\n",
    "I suppose the differences come from different versions of the LM-Eval harness (I further assume EleutherAI used their own LM Eval harness to test their models, still, speculative) being used and thus processing differences. I can't deem this to be a source of error in any way though.\n",
    "\n",
    "Given a notable divergence of performance results only occuring for Lambada, I interpret the deviation as a result of evaluation harness variance too.\n",
    "\n",
    "We can go ahead and evaluate Pythia $160\\text{M}$ MiniPile with the same setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoXForCausalLM were not initialized from the model checkpoint at /mnt/data/pythia160m_minipile_trained and are newly initialized: ['embed_out.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2024-11-18:18:11:33,482 WARNING  [huggingface.py:95] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2024-11-18:18:11:33,483 INFO     [huggingface.py:481] Using model type 'default'\n",
      "2024-11-18:18:11:33,497 WARNING  [huggingface.py:275] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "2024-11-18:18:11:33,500 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2024-11-18:18:11:33,500 INFO     [evaluator.py:217] Using pre-initialized model\n",
      "2024-11-18:18:11:38,295 INFO     [__init__.py:459] The tag 'arc_ca' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-11-18:18:11:38,314 INFO     [__init__.py:459] The tag 'arc_ca' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2024-11-18:18:14:25,213 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-11-18:18:14:25,214 WARNING  [task.py:325] [Task: lambada_openai] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-11-18:18:14:29,423 WARNING  [task.py:799] [Task: blimp_wh_vs_that_with_gap_long_distance] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:14:29,424 WARNING  [task.py:811] [Task: blimp_wh_vs_that_with_gap_long_distance] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:14:32,249 WARNING  [task.py:799] [Task: blimp_wh_vs_that_with_gap] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:14:32,250 WARNING  [task.py:811] [Task: blimp_wh_vs_that_with_gap] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:14:34,924 WARNING  [task.py:799] [Task: blimp_wh_vs_that_no_gap_long_distance] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:14:34,925 WARNING  [task.py:811] [Task: blimp_wh_vs_that_no_gap_long_distance] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:14:37,401 WARNING  [task.py:799] [Task: blimp_wh_vs_that_no_gap] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:14:37,402 WARNING  [task.py:811] [Task: blimp_wh_vs_that_no_gap] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:14:39,840 WARNING  [task.py:799] [Task: blimp_wh_questions_subject_gap_long_distance] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:14:39,841 WARNING  [task.py:811] [Task: blimp_wh_questions_subject_gap_long_distance] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:14:42,311 WARNING  [task.py:799] [Task: blimp_wh_questions_subject_gap] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:14:42,312 WARNING  [task.py:811] [Task: blimp_wh_questions_subject_gap] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:14:44,709 WARNING  [task.py:799] [Task: blimp_wh_questions_object_gap] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:14:44,710 WARNING  [task.py:811] [Task: blimp_wh_questions_object_gap] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:14:48,730 WARNING  [task.py:799] [Task: blimp_wh_island] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:14:48,731 WARNING  [task.py:811] [Task: blimp_wh_island] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:14:51,072 WARNING  [task.py:799] [Task: blimp_transitive] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:14:51,073 WARNING  [task.py:811] [Task: blimp_transitive] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:14:53,443 WARNING  [task.py:799] [Task: blimp_tough_vs_raising_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:14:53,444 WARNING  [task.py:811] [Task: blimp_tough_vs_raising_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:14:55,885 WARNING  [task.py:799] [Task: blimp_tough_vs_raising_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:14:55,886 WARNING  [task.py:811] [Task: blimp_tough_vs_raising_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:14:58,276 WARNING  [task.py:799] [Task: blimp_superlative_quantifiers_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:14:58,277 WARNING  [task.py:811] [Task: blimp_superlative_quantifiers_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:00,786 WARNING  [task.py:799] [Task: blimp_superlative_quantifiers_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:00,787 WARNING  [task.py:811] [Task: blimp_superlative_quantifiers_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:03,208 WARNING  [task.py:799] [Task: blimp_sentential_subject_island] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:03,209 WARNING  [task.py:811] [Task: blimp_sentential_subject_island] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:05,626 WARNING  [task.py:799] [Task: blimp_sentential_negation_npi_scope] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:05,628 WARNING  [task.py:811] [Task: blimp_sentential_negation_npi_scope] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:07,979 WARNING  [task.py:799] [Task: blimp_sentential_negation_npi_licensor_present] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:07,980 WARNING  [task.py:811] [Task: blimp_sentential_negation_npi_licensor_present] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:10,321 WARNING  [task.py:799] [Task: blimp_regular_plural_subject_verb_agreement_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:10,322 WARNING  [task.py:811] [Task: blimp_regular_plural_subject_verb_agreement_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:12,704 WARNING  [task.py:799] [Task: blimp_regular_plural_subject_verb_agreement_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:12,705 WARNING  [task.py:811] [Task: blimp_regular_plural_subject_verb_agreement_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:15,109 WARNING  [task.py:799] [Task: blimp_principle_A_reconstruction] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:15,110 WARNING  [task.py:811] [Task: blimp_principle_A_reconstruction] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:17,674 WARNING  [task.py:799] [Task: blimp_principle_A_domain_3] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:17,675 WARNING  [task.py:811] [Task: blimp_principle_A_domain_3] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:20,412 WARNING  [task.py:799] [Task: blimp_principle_A_domain_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:20,413 WARNING  [task.py:811] [Task: blimp_principle_A_domain_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:22,774 WARNING  [task.py:799] [Task: blimp_principle_A_domain_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:22,775 WARNING  [task.py:811] [Task: blimp_principle_A_domain_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:25,442 WARNING  [task.py:799] [Task: blimp_principle_A_case_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:25,443 WARNING  [task.py:811] [Task: blimp_principle_A_case_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:28,083 WARNING  [task.py:799] [Task: blimp_principle_A_case_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:28,084 WARNING  [task.py:811] [Task: blimp_principle_A_case_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:30,536 WARNING  [task.py:799] [Task: blimp_principle_A_c_command] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:30,537 WARNING  [task.py:811] [Task: blimp_principle_A_c_command] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:32,975 WARNING  [task.py:799] [Task: blimp_passive_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:32,976 WARNING  [task.py:811] [Task: blimp_passive_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:35,324 WARNING  [task.py:799] [Task: blimp_passive_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:35,325 WARNING  [task.py:811] [Task: blimp_passive_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:37,726 WARNING  [task.py:799] [Task: blimp_only_npi_scope] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:37,726 WARNING  [task.py:811] [Task: blimp_only_npi_scope] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:40,933 WARNING  [task.py:799] [Task: blimp_only_npi_licensor_present] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:40,934 WARNING  [task.py:811] [Task: blimp_only_npi_licensor_present] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:43,292 WARNING  [task.py:799] [Task: blimp_npi_present_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:43,293 WARNING  [task.py:811] [Task: blimp_npi_present_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:45,797 WARNING  [task.py:799] [Task: blimp_npi_present_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:45,798 WARNING  [task.py:811] [Task: blimp_npi_present_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:48,193 WARNING  [task.py:799] [Task: blimp_matrix_question_npi_licensor_present] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:48,194 WARNING  [task.py:811] [Task: blimp_matrix_question_npi_licensor_present] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:50,598 WARNING  [task.py:799] [Task: blimp_left_branch_island_simple_question] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:50,599 WARNING  [task.py:811] [Task: blimp_left_branch_island_simple_question] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:52,973 WARNING  [task.py:799] [Task: blimp_left_branch_island_echo_question] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:52,974 WARNING  [task.py:811] [Task: blimp_left_branch_island_echo_question] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:55,367 WARNING  [task.py:799] [Task: blimp_irregular_plural_subject_verb_agreement_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:55,369 WARNING  [task.py:811] [Task: blimp_irregular_plural_subject_verb_agreement_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:15:57,847 WARNING  [task.py:799] [Task: blimp_irregular_plural_subject_verb_agreement_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:15:57,848 WARNING  [task.py:811] [Task: blimp_irregular_plural_subject_verb_agreement_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:00,248 WARNING  [task.py:799] [Task: blimp_irregular_past_participle_verbs] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:00,249 WARNING  [task.py:811] [Task: blimp_irregular_past_participle_verbs] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:02,626 WARNING  [task.py:799] [Task: blimp_irregular_past_participle_adjectives] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:02,627 WARNING  [task.py:811] [Task: blimp_irregular_past_participle_adjectives] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:04,968 WARNING  [task.py:799] [Task: blimp_intransitive] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:04,969 WARNING  [task.py:811] [Task: blimp_intransitive] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:07,458 WARNING  [task.py:799] [Task: blimp_inchoative] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:07,459 WARNING  [task.py:811] [Task: blimp_inchoative] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:09,918 WARNING  [task.py:799] [Task: blimp_expletive_it_object_raising] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:09,919 WARNING  [task.py:811] [Task: blimp_expletive_it_object_raising] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:12,321 WARNING  [task.py:799] [Task: blimp_existential_there_subject_raising] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:12,322 WARNING  [task.py:811] [Task: blimp_existential_there_subject_raising] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:15,925 WARNING  [task.py:799] [Task: blimp_existential_there_quantifiers_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:15,926 WARNING  [task.py:811] [Task: blimp_existential_there_quantifiers_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:18,308 WARNING  [task.py:799] [Task: blimp_existential_there_quantifiers_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:18,309 WARNING  [task.py:811] [Task: blimp_existential_there_quantifiers_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:20,750 WARNING  [task.py:799] [Task: blimp_existential_there_object_raising] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:20,751 WARNING  [task.py:811] [Task: blimp_existential_there_object_raising] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:23,170 WARNING  [task.py:799] [Task: blimp_ellipsis_n_bar_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:23,171 WARNING  [task.py:811] [Task: blimp_ellipsis_n_bar_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:25,566 WARNING  [task.py:799] [Task: blimp_ellipsis_n_bar_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:25,567 WARNING  [task.py:811] [Task: blimp_ellipsis_n_bar_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:28,131 WARNING  [task.py:799] [Task: blimp_drop_argument] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:28,132 WARNING  [task.py:811] [Task: blimp_drop_argument] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:30,867 WARNING  [task.py:799] [Task: blimp_distractor_agreement_relative_clause] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:30,868 WARNING  [task.py:811] [Task: blimp_distractor_agreement_relative_clause] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:34,245 WARNING  [task.py:799] [Task: blimp_distractor_agreement_relational_noun] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:34,246 WARNING  [task.py:811] [Task: blimp_distractor_agreement_relational_noun] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:36,730 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_with_adjective_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:36,731 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_with_adjective_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:39,353 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_with_adj_irregular_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:39,354 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_with_adj_irregular_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:41,776 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_with_adj_irregular_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:41,777 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_with_adj_irregular_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:44,164 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_with_adj_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:44,164 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_with_adj_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:46,775 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_irregular_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:46,776 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_irregular_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:49,237 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_irregular_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:49,238 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_irregular_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:51,635 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_2] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:51,636 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_2] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:54,322 WARNING  [task.py:799] [Task: blimp_determiner_noun_agreement_1] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:54,323 WARNING  [task.py:811] [Task: blimp_determiner_noun_agreement_1] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:56,936 WARNING  [task.py:799] [Task: blimp_coordinate_structure_constraint_object_extraction] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:56,938 WARNING  [task.py:811] [Task: blimp_coordinate_structure_constraint_object_extraction] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:16:59,367 WARNING  [task.py:799] [Task: blimp_coordinate_structure_constraint_complex_left_branch] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:16:59,368 WARNING  [task.py:811] [Task: blimp_coordinate_structure_constraint_complex_left_branch] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:17:01,777 WARNING  [task.py:799] [Task: blimp_complex_NP_island] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:17:01,778 WARNING  [task.py:811] [Task: blimp_complex_NP_island] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:17:04,140 WARNING  [task.py:799] [Task: blimp_causative] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:17:04,141 WARNING  [task.py:811] [Task: blimp_causative] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:17:06,493 WARNING  [task.py:799] [Task: blimp_animate_subject_trans] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:17:06,494 WARNING  [task.py:811] [Task: blimp_animate_subject_trans] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:17:08,929 WARNING  [task.py:799] [Task: blimp_animate_subject_passive] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:17:08,930 WARNING  [task.py:811] [Task: blimp_animate_subject_passive] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:17:11,298 WARNING  [task.py:799] [Task: blimp_anaphor_number_agreement] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:17:11,299 WARNING  [task.py:811] [Task: blimp_anaphor_number_agreement] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:17:13,710 WARNING  [task.py:799] [Task: blimp_anaphor_gender_agreement] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:17:13,711 WARNING  [task.py:811] [Task: blimp_anaphor_gender_agreement] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:17:16,214 WARNING  [task.py:799] [Task: blimp_adjunct_island] metric acc is defined, but aggregation is not. using default aggregation=mean\n",
      "2024-11-18:18:17:16,215 WARNING  [task.py:811] [Task: blimp_adjunct_island] metric acc is defined, but higher_is_better is not. using default higher_is_better=True\n",
      "2024-11-18:18:17:18,578 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_adjunct_island in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,579 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_anaphor_gender_agreement in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,580 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_anaphor_number_agreement in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,581 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_animate_subject_passive in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,583 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_animate_subject_trans in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,583 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_causative in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,584 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_complex_NP_island in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,585 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_coordinate_structure_constraint_complex_left_branch in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,585 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_coordinate_structure_constraint_object_extraction in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,586 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,587 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,588 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_irregular_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,589 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_irregular_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,589 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_with_adj_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,590 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_with_adj_irregular_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,591 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_with_adj_irregular_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,592 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_determiner_noun_agreement_with_adjective_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,595 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_distractor_agreement_relational_noun in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,595 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_distractor_agreement_relative_clause in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,596 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_drop_argument in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,597 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_ellipsis_n_bar_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,597 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_ellipsis_n_bar_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,598 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_existential_there_object_raising in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,598 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_existential_there_quantifiers_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,600 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_existential_there_quantifiers_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,600 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_existential_there_subject_raising in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,601 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_expletive_it_object_raising in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,601 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_inchoative in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,602 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_intransitive in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,602 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_irregular_past_participle_adjectives in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,603 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_irregular_past_participle_verbs in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,604 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_irregular_plural_subject_verb_agreement_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,604 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_irregular_plural_subject_verb_agreement_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,605 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_left_branch_island_echo_question in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,605 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_left_branch_island_simple_question in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,606 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_matrix_question_npi_licensor_present in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,606 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_npi_present_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,607 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_npi_present_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,607 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_only_npi_licensor_present in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,608 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_only_npi_scope in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,609 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_passive_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,609 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_passive_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,610 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_principle_A_c_command in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,611 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_principle_A_case_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,612 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_principle_A_case_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,613 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_principle_A_domain_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,614 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_principle_A_domain_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,614 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_principle_A_domain_3 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,615 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_principle_A_reconstruction in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,616 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_regular_plural_subject_verb_agreement_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,617 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_regular_plural_subject_verb_agreement_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,617 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_sentential_negation_npi_licensor_present in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,618 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_sentential_negation_npi_scope in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,619 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_sentential_subject_island in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,620 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_superlative_quantifiers_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,621 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_superlative_quantifiers_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,621 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_tough_vs_raising_1 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,622 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_tough_vs_raising_2 in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,623 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_transitive in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,624 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_island in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,625 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_questions_object_gap in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,626 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_questions_subject_gap in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,627 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_questions_subject_gap_long_distance in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,627 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_vs_that_no_gap in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,628 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_vs_that_no_gap_long_distance in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,629 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_vs_that_with_gap in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,631 INFO     [evaluator.py:266] num_fewshot has been set to 0 for blimp_wh_vs_that_with_gap_long_distance in its config. Manual configuration will be ignored.\n",
      "2024-11-18:18:17:18,631 WARNING  [evaluator.py:270] Overwriting default num_fewshot of lambada_standard from None to 0\n",
      "2024-11-18:18:17:18,632 WARNING  [evaluator.py:270] Overwriting default num_fewshot of lambada_openai from None to 0\n",
      "2024-11-18:18:17:18,633 WARNING  [evaluator.py:270] Overwriting default num_fewshot of hellaswag from None to 0\n",
      "2024-11-18:18:17:18,634 WARNING  [evaluator.py:270] Overwriting default num_fewshot of winogrande from None to 0\n",
      "2024-11-18:18:17:18,634 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
      "2024-11-18:18:17:18,635 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
      "2024-11-18:18:17:18,636 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
      "2024-11-18:18:17:18,637 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
      "2024-11-18:18:17:18,638 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
      "2024-11-18:18:17:18,639 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
      "2024-11-18:18:17:18,639 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
      "2024-11-18:18:17:18,640 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
      "2024-11-18:18:17:18,641 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
      "2024-11-18:18:17:18,642 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
      "2024-11-18:18:17:18,643 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
      "2024-11-18:18:17:18,643 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
      "2024-11-18:18:17:18,644 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
      "2024-11-18:18:17:18,645 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
      "2024-11-18:18:17:18,646 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
      "2024-11-18:18:17:18,647 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
      "2024-11-18:18:17:18,648 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
      "2024-11-18:18:17:18,649 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
      "2024-11-18:18:17:18,649 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
      "2024-11-18:18:17:18,650 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
      "2024-11-18:18:17:18,651 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
      "2024-11-18:18:17:18,652 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
      "2024-11-18:18:17:18,653 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
      "2024-11-18:18:17:18,654 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
      "2024-11-18:18:17:18,655 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_management from None to 0\n",
      "2024-11-18:18:17:18,656 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
      "2024-11-18:18:17:18,657 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
      "2024-11-18:18:17:18,658 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
      "2024-11-18:18:17:18,659 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
      "2024-11-18:18:17:18,660 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
      "2024-11-18:18:17:18,660 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
      "2024-11-18:18:17:18,661 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
      "2024-11-18:18:17:18,663 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
      "2024-11-18:18:17:18,664 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
      "2024-11-18:18:17:18,665 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
      "2024-11-18:18:17:18,666 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
      "2024-11-18:18:17:18,666 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
      "2024-11-18:18:17:18,667 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
      "2024-11-18:18:17:18,668 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
      "2024-11-18:18:17:18,669 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
      "2024-11-18:18:17:18,670 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
      "2024-11-18:18:17:18,671 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
      "2024-11-18:18:17:18,671 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
      "2024-11-18:18:17:18,672 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
      "2024-11-18:18:17:18,673 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
      "2024-11-18:18:17:18,674 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
      "2024-11-18:18:17:18,675 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
      "2024-11-18:18:17:18,676 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
      "2024-11-18:18:17:18,676 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
      "2024-11-18:18:17:18,677 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
      "2024-11-18:18:17:18,678 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
      "2024-11-18:18:17:18,679 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
      "2024-11-18:18:17:18,680 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
      "2024-11-18:18:17:18,681 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
      "2024-11-18:18:17:18,681 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
      "2024-11-18:18:17:18,682 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
      "2024-11-18:18:17:18,683 WARNING  [evaluator.py:270] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
      "2024-11-18:18:17:18,684 WARNING  [evaluator.py:270] Overwriting default num_fewshot of arc_challenge from None to 0\n",
      "2024-11-18:18:17:18,696 INFO     [task.py:415] Building contexts for blimp_adjunct_island on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 877.03it/s]\n",
      "2024-11-18:18:17:20,060 INFO     [task.py:415] Building contexts for blimp_anaphor_gender_agreement on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 879.60it/s]\n",
      "2024-11-18:18:17:21,371 INFO     [task.py:415] Building contexts for blimp_anaphor_number_agreement on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 848.21it/s]\n",
      "2024-11-18:18:17:22,729 INFO     [task.py:415] Building contexts for blimp_animate_subject_passive on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 889.49it/s]\n",
      "2024-11-18:18:17:24,029 INFO     [task.py:415] Building contexts for blimp_animate_subject_trans on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 891.85it/s]\n",
      "2024-11-18:18:17:25,324 INFO     [task.py:415] Building contexts for blimp_causative on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 516.42it/s]\n",
      "2024-11-18:18:17:27,433 INFO     [task.py:415] Building contexts for blimp_complex_NP_island on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 879.85it/s]\n",
      "2024-11-18:18:17:28,743 INFO     [task.py:415] Building contexts for blimp_coordinate_structure_constraint_complex_left_branch on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 878.38it/s]\n",
      "2024-11-18:18:17:30,057 INFO     [task.py:415] Building contexts for blimp_coordinate_structure_constraint_object_extraction on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 882.01it/s]\n",
      "2024-11-18:18:17:31,367 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 891.11it/s]\n",
      "2024-11-18:18:17:32,662 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 890.14it/s]\n",
      "2024-11-18:18:17:33,957 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_irregular_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 890.96it/s]\n",
      "2024-11-18:18:17:35,254 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_irregular_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 879.93it/s]\n",
      "2024-11-18:18:17:36,564 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_with_adj_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 887.79it/s]\n",
      "2024-11-18:18:17:37,866 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_with_adj_irregular_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 889.72it/s]\n",
      "2024-11-18:18:17:39,180 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_with_adj_irregular_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 888.61it/s]\n",
      "2024-11-18:18:17:40,478 INFO     [task.py:415] Building contexts for blimp_determiner_noun_agreement_with_adjective_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 888.11it/s]\n",
      "2024-11-18:18:17:41,779 INFO     [task.py:415] Building contexts for blimp_distractor_agreement_relational_noun on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 886.92it/s]\n",
      "2024-11-18:18:17:43,080 INFO     [task.py:415] Building contexts for blimp_distractor_agreement_relative_clause on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 871.80it/s]\n",
      "2024-11-18:18:17:44,406 INFO     [task.py:415] Building contexts for blimp_drop_argument on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 868.93it/s]\n",
      "2024-11-18:18:17:45,736 INFO     [task.py:415] Building contexts for blimp_ellipsis_n_bar_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 866.16it/s]\n",
      "2024-11-18:18:17:47,065 INFO     [task.py:415] Building contexts for blimp_ellipsis_n_bar_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 870.26it/s]\n",
      "2024-11-18:18:17:48,395 INFO     [task.py:415] Building contexts for blimp_existential_there_object_raising on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 867.91it/s]\n",
      "2024-11-18:18:17:49,722 INFO     [task.py:415] Building contexts for blimp_existential_there_quantifiers_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 889.36it/s]\n",
      "2024-11-18:18:17:51,018 INFO     [task.py:415] Building contexts for blimp_existential_there_quantifiers_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 880.85it/s]\n",
      "2024-11-18:18:17:52,328 INFO     [task.py:415] Building contexts for blimp_existential_there_subject_raising on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 870.57it/s]\n",
      "2024-11-18:18:17:53,662 INFO     [task.py:415] Building contexts for blimp_expletive_it_object_raising on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 876.97it/s]\n",
      "2024-11-18:18:17:54,976 INFO     [task.py:415] Building contexts for blimp_inchoative on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 866.95it/s]\n",
      "2024-11-18:18:17:56,304 INFO     [task.py:415] Building contexts for blimp_intransitive on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 869.92it/s]\n",
      "2024-11-18:18:17:57,630 INFO     [task.py:415] Building contexts for blimp_irregular_past_participle_adjectives on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 863.03it/s]\n",
      "2024-11-18:18:17:58,966 INFO     [task.py:415] Building contexts for blimp_irregular_past_participle_verbs on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 874.97it/s]\n",
      "2024-11-18:18:18:00,284 INFO     [task.py:415] Building contexts for blimp_irregular_plural_subject_verb_agreement_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 881.64it/s]\n",
      "2024-11-18:18:18:01,597 INFO     [task.py:415] Building contexts for blimp_irregular_plural_subject_verb_agreement_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 872.09it/s]\n",
      "2024-11-18:18:18:02,918 INFO     [task.py:415] Building contexts for blimp_left_branch_island_echo_question on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 884.94it/s]\n",
      "2024-11-18:18:18:04,222 INFO     [task.py:415] Building contexts for blimp_left_branch_island_simple_question on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 875.82it/s]\n",
      "2024-11-18:18:18:05,566 INFO     [task.py:415] Building contexts for blimp_matrix_question_npi_licensor_present on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 870.38it/s]\n",
      "2024-11-18:18:18:06,895 INFO     [task.py:415] Building contexts for blimp_npi_present_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 864.90it/s]\n",
      "2024-11-18:18:18:08,227 INFO     [task.py:415] Building contexts for blimp_npi_present_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 791.62it/s]\n",
      "2024-11-18:18:18:09,680 INFO     [task.py:415] Building contexts for blimp_only_npi_licensor_present on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 872.47it/s]\n",
      "2024-11-18:18:18:11,007 INFO     [task.py:415] Building contexts for blimp_only_npi_scope on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 816.11it/s]\n",
      "2024-11-18:18:18:12,419 INFO     [task.py:415] Building contexts for blimp_passive_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 904.49it/s]\n",
      "2024-11-18:18:18:13,700 INFO     [task.py:415] Building contexts for blimp_passive_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 885.98it/s]\n",
      "2024-11-18:18:18:14,999 INFO     [task.py:415] Building contexts for blimp_principle_A_c_command on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 881.45it/s]\n",
      "2024-11-18:18:18:16,307 INFO     [task.py:415] Building contexts for blimp_principle_A_case_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 880.72it/s]\n",
      "2024-11-18:18:18:17,620 INFO     [task.py:415] Building contexts for blimp_principle_A_case_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 882.54it/s]\n",
      "2024-11-18:18:18:18,927 INFO     [task.py:415] Building contexts for blimp_principle_A_domain_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 875.86it/s]\n",
      "2024-11-18:18:18:20,243 INFO     [task.py:415] Building contexts for blimp_principle_A_domain_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 864.19it/s]\n",
      "2024-11-18:18:18:21,576 INFO     [task.py:415] Building contexts for blimp_principle_A_domain_3 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 878.61it/s]\n",
      "2024-11-18:18:18:22,891 INFO     [task.py:415] Building contexts for blimp_principle_A_reconstruction on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 881.37it/s]\n",
      "2024-11-18:18:18:24,202 INFO     [task.py:415] Building contexts for blimp_regular_plural_subject_verb_agreement_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 870.75it/s]\n",
      "2024-11-18:18:18:25,525 INFO     [task.py:415] Building contexts for blimp_regular_plural_subject_verb_agreement_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 894.39it/s]\n",
      "2024-11-18:18:18:26,817 INFO     [task.py:415] Building contexts for blimp_sentential_negation_npi_licensor_present on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 876.90it/s]\n",
      "2024-11-18:18:18:28,130 INFO     [task.py:415] Building contexts for blimp_sentential_negation_npi_scope on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 883.24it/s]\n",
      "2024-11-18:18:18:29,436 INFO     [task.py:415] Building contexts for blimp_sentential_subject_island on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 877.98it/s]\n",
      "2024-11-18:18:18:30,747 INFO     [task.py:415] Building contexts for blimp_superlative_quantifiers_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 894.54it/s]\n",
      "2024-11-18:18:18:32,039 INFO     [task.py:415] Building contexts for blimp_superlative_quantifiers_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 878.18it/s]\n",
      "2024-11-18:18:18:33,350 INFO     [task.py:415] Building contexts for blimp_tough_vs_raising_1 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 905.27it/s]\n",
      "2024-11-18:18:18:34,631 INFO     [task.py:415] Building contexts for blimp_tough_vs_raising_2 on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 885.59it/s]\n",
      "2024-11-18:18:18:35,931 INFO     [task.py:415] Building contexts for blimp_transitive on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 905.71it/s]\n",
      "2024-11-18:18:18:37,206 INFO     [task.py:415] Building contexts for blimp_wh_island on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 903.93it/s]\n",
      "2024-11-18:18:18:38,486 INFO     [task.py:415] Building contexts for blimp_wh_questions_object_gap on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 900.32it/s]\n",
      "2024-11-18:18:18:39,768 INFO     [task.py:415] Building contexts for blimp_wh_questions_subject_gap on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 869.45it/s]\n",
      "2024-11-18:18:18:41,100 INFO     [task.py:415] Building contexts for blimp_wh_questions_subject_gap_long_distance on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 868.96it/s]\n",
      "2024-11-18:18:18:42,436 INFO     [task.py:415] Building contexts for blimp_wh_vs_that_no_gap on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 895.51it/s]\n",
      "2024-11-18:18:18:43,723 INFO     [task.py:415] Building contexts for blimp_wh_vs_that_no_gap_long_distance on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 904.82it/s]\n",
      "2024-11-18:18:18:44,999 INFO     [task.py:415] Building contexts for blimp_wh_vs_that_with_gap on rank 0...\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 908.94it/s]\n",
      "2024-11-18:18:18:46,269 INFO     [task.py:415] Building contexts for blimp_wh_vs_that_with_gap_long_distance on rank 0...\n",
      "100%|██████████| 1000/1000 [00:02<00:00, 480.92it/s]\n",
      "2024-11-18:18:18:48,521 INFO     [task.py:415] Building contexts for lambada_standard on rank 0...\n",
      "100%|██████████| 5153/5153 [00:13<00:00, 387.88it/s]\n",
      "2024-11-18:18:19:02,090 INFO     [task.py:415] Building contexts for lambada_openai on rank 0...\n",
      "100%|██████████| 5153/5153 [00:13<00:00, 388.59it/s]\n",
      "2024-11-18:18:19:15,574 INFO     [task.py:415] Building contexts for hellaswag on rank 0...\n",
      "100%|██████████| 10042/10042 [00:05<00:00, 1783.26it/s]\n",
      "2024-11-18:18:19:23,663 INFO     [task.py:415] Building contexts for winogrande on rank 0...\n",
      "100%|██████████| 1267/1267 [00:00<00:00, 50048.81it/s]\n",
      "2024-11-18:18:19:23,800 INFO     [task.py:415] Building contexts for mmlu_machine_learning on rank 0...\n",
      "100%|██████████| 112/112 [00:00<00:00, 430.93it/s]\n",
      "2024-11-18:18:19:24,075 INFO     [task.py:415] Building contexts for mmlu_astronomy on rank 0...\n",
      "100%|██████████| 152/152 [00:00<00:00, 433.87it/s]\n",
      "2024-11-18:18:19:24,445 INFO     [task.py:415] Building contexts for mmlu_college_mathematics on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 433.40it/s]\n",
      "2024-11-18:18:19:24,689 INFO     [task.py:415] Building contexts for mmlu_high_school_physics on rank 0...\n",
      "100%|██████████| 151/151 [00:00<00:00, 402.90it/s]\n",
      "2024-11-18:18:19:25,086 INFO     [task.py:415] Building contexts for mmlu_high_school_biology on rank 0...\n",
      "100%|██████████| 310/310 [00:00<00:00, 410.92it/s]\n",
      "2024-11-18:18:19:25,878 INFO     [task.py:415] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
      "100%|██████████| 270/270 [00:00<00:00, 433.62it/s]\n",
      "2024-11-18:18:19:26,532 INFO     [task.py:415] Building contexts for mmlu_college_computer_science on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 422.30it/s]\n",
      "2024-11-18:18:19:26,783 INFO     [task.py:415] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
      "100%|██████████| 378/378 [00:00<00:00, 432.83it/s]\n",
      "2024-11-18:18:19:27,700 INFO     [task.py:415] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
      "100%|██████████| 203/203 [00:00<00:00, 430.39it/s]\n",
      "2024-11-18:18:19:28,196 INFO     [task.py:415] Building contexts for mmlu_conceptual_physics on rank 0...\n",
      "100%|██████████| 235/235 [00:00<00:00, 428.30it/s]\n",
      "2024-11-18:18:19:28,772 INFO     [task.py:415] Building contexts for mmlu_computer_security on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 429.35it/s]\n",
      "2024-11-18:18:19:29,018 INFO     [task.py:415] Building contexts for mmlu_electrical_engineering on rank 0...\n",
      "100%|██████████| 145/145 [00:00<00:00, 431.22it/s]\n",
      "2024-11-18:18:19:29,373 INFO     [task.py:415] Building contexts for mmlu_anatomy on rank 0...\n",
      "100%|██████████| 135/135 [00:00<00:00, 428.74it/s]\n",
      "2024-11-18:18:19:29,706 INFO     [task.py:415] Building contexts for mmlu_college_chemistry on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 428.93it/s]\n",
      "2024-11-18:18:19:29,954 INFO     [task.py:415] Building contexts for mmlu_college_physics on rank 0...\n",
      "100%|██████████| 102/102 [00:00<00:00, 425.81it/s]\n",
      "2024-11-18:18:19:30,208 INFO     [task.py:415] Building contexts for mmlu_abstract_algebra on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 425.18it/s]\n",
      "2024-11-18:18:19:30,457 INFO     [task.py:415] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 430.10it/s]\n",
      "2024-11-18:18:19:30,703 INFO     [task.py:415] Building contexts for mmlu_college_biology on rank 0...\n",
      "100%|██████████| 144/144 [00:00<00:00, 430.44it/s]\n",
      "2024-11-18:18:19:31,055 INFO     [task.py:415] Building contexts for mmlu_high_school_statistics on rank 0...\n",
      "100%|██████████| 216/216 [00:00<00:00, 431.53it/s]\n",
      "2024-11-18:18:19:31,582 INFO     [task.py:415] Building contexts for mmlu_global_facts on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 431.14it/s]\n",
      "2024-11-18:18:19:31,827 INFO     [task.py:415] Building contexts for mmlu_marketing on rank 0...\n",
      "100%|██████████| 234/234 [00:00<00:00, 421.84it/s]\n",
      "2024-11-18:18:19:32,409 INFO     [task.py:415] Building contexts for mmlu_nutrition on rank 0...\n",
      "100%|██████████| 306/306 [00:00<00:00, 426.08it/s]\n",
      "2024-11-18:18:19:33,162 INFO     [task.py:415] Building contexts for mmlu_college_medicine on rank 0...\n",
      "100%|██████████| 173/173 [00:00<00:00, 423.88it/s]\n",
      "2024-11-18:18:19:33,592 INFO     [task.py:415] Building contexts for mmlu_business_ethics on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 436.49it/s]\n",
      "2024-11-18:18:19:33,835 INFO     [task.py:415] Building contexts for mmlu_management on rank 0...\n",
      "100%|██████████| 103/103 [00:00<00:00, 425.78it/s]\n",
      "2024-11-18:18:19:34,091 INFO     [task.py:415] Building contexts for mmlu_virology on rank 0...\n",
      "100%|██████████| 166/166 [00:00<00:00, 432.14it/s]\n",
      "2024-11-18:18:19:34,495 INFO     [task.py:415] Building contexts for mmlu_human_aging on rank 0...\n",
      "100%|██████████| 223/223 [00:00<00:00, 428.62it/s]\n",
      "2024-11-18:18:19:35,042 INFO     [task.py:415] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
      "100%|██████████| 265/265 [00:00<00:00, 431.08it/s]\n",
      "2024-11-18:18:19:35,687 INFO     [task.py:415] Building contexts for mmlu_medical_genetics on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 402.58it/s]\n",
      "2024-11-18:18:19:35,949 INFO     [task.py:415] Building contexts for mmlu_professional_medicine on rank 0...\n",
      "100%|██████████| 272/272 [00:00<00:00, 418.96it/s]\n",
      "2024-11-18:18:19:36,630 INFO     [task.py:415] Building contexts for mmlu_professional_accounting on rank 0...\n",
      "100%|██████████| 282/282 [00:00<00:00, 416.60it/s]\n",
      "2024-11-18:18:19:37,342 INFO     [task.py:415] Building contexts for mmlu_miscellaneous on rank 0...\n",
      "100%|██████████| 783/783 [00:01<00:00, 436.98it/s]\n",
      "2024-11-18:18:19:39,216 INFO     [task.py:415] Building contexts for mmlu_econometrics on rank 0...\n",
      "100%|██████████| 114/114 [00:00<00:00, 437.67it/s]\n",
      "2024-11-18:18:19:39,492 INFO     [task.py:415] Building contexts for mmlu_professional_psychology on rank 0...\n",
      "100%|██████████| 612/612 [00:01<00:00, 438.36it/s]\n",
      "2024-11-18:18:19:40,952 INFO     [task.py:415] Building contexts for mmlu_high_school_psychology on rank 0...\n",
      "100%|██████████| 545/545 [00:01<00:00, 434.45it/s]\n",
      "2024-11-18:18:19:42,264 INFO     [task.py:415] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
      "100%|██████████| 193/193 [00:00<00:00, 438.50it/s]\n",
      "2024-11-18:18:19:42,728 INFO     [task.py:415] Building contexts for mmlu_sociology on rank 0...\n",
      "100%|██████████| 201/201 [00:00<00:00, 439.38it/s]\n",
      "2024-11-18:18:19:43,209 INFO     [task.py:415] Building contexts for mmlu_human_sexuality on rank 0...\n",
      "100%|██████████| 131/131 [00:00<00:00, 439.97it/s]\n",
      "2024-11-18:18:19:43,523 INFO     [task.py:415] Building contexts for mmlu_high_school_geography on rank 0...\n",
      "100%|██████████| 198/198 [00:00<00:00, 440.56it/s]\n",
      "2024-11-18:18:19:43,996 INFO     [task.py:415] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
      "100%|██████████| 390/390 [00:00<00:00, 435.01it/s]\n",
      "2024-11-18:18:19:44,935 INFO     [task.py:415] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
      "100%|██████████| 238/238 [00:00<00:00, 433.93it/s]\n",
      "2024-11-18:18:19:45,510 INFO     [task.py:415] Building contexts for mmlu_public_relations on rank 0...\n",
      "100%|██████████| 110/110 [00:00<00:00, 423.81it/s]\n",
      "2024-11-18:18:19:45,785 INFO     [task.py:415] Building contexts for mmlu_security_studies on rank 0...\n",
      "100%|██████████| 245/245 [00:00<00:00, 431.99it/s]\n",
      "2024-11-18:18:19:46,381 INFO     [task.py:415] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 431.65it/s]\n",
      "2024-11-18:18:19:46,627 INFO     [task.py:415] Building contexts for mmlu_international_law on rank 0...\n",
      "100%|██████████| 121/121 [00:00<00:00, 432.60it/s]\n",
      "2024-11-18:18:19:46,922 INFO     [task.py:415] Building contexts for mmlu_high_school_european_history on rank 0...\n",
      "100%|██████████| 165/165 [00:00<00:00, 429.27it/s]\n",
      "2024-11-18:18:19:47,331 INFO     [task.py:415] Building contexts for mmlu_philosophy on rank 0...\n",
      "100%|██████████| 311/311 [00:00<00:00, 426.49it/s]\n",
      "2024-11-18:18:19:48,096 INFO     [task.py:415] Building contexts for mmlu_moral_scenarios on rank 0...\n",
      "100%|██████████| 895/895 [00:02<00:00, 422.82it/s]\n",
      "2024-11-18:18:19:50,308 INFO     [task.py:415] Building contexts for mmlu_jurisprudence on rank 0...\n",
      "100%|██████████| 108/108 [00:00<00:00, 382.24it/s]\n",
      "2024-11-18:18:19:50,610 INFO     [task.py:415] Building contexts for mmlu_formal_logic on rank 0...\n",
      "100%|██████████| 126/126 [00:00<00:00, 377.24it/s]\n",
      "2024-11-18:18:19:50,966 INFO     [task.py:415] Building contexts for mmlu_world_religions on rank 0...\n",
      "100%|██████████| 171/171 [00:00<00:00, 388.36it/s]\n",
      "2024-11-18:18:19:51,432 INFO     [task.py:415] Building contexts for mmlu_prehistory on rank 0...\n",
      "100%|██████████| 324/324 [00:00<00:00, 371.28it/s]\n",
      "2024-11-18:18:19:52,353 INFO     [task.py:415] Building contexts for mmlu_high_school_us_history on rank 0...\n",
      "100%|██████████| 204/204 [00:00<00:00, 379.37it/s]\n",
      "2024-11-18:18:19:52,925 INFO     [task.py:415] Building contexts for mmlu_moral_disputes on rank 0...\n",
      "100%|██████████| 346/346 [00:00<00:00, 409.84it/s]\n",
      "2024-11-18:18:19:53,819 INFO     [task.py:415] Building contexts for mmlu_logical_fallacies on rank 0...\n",
      "100%|██████████| 163/163 [00:00<00:00, 431.59it/s]\n",
      "2024-11-18:18:19:54,217 INFO     [task.py:415] Building contexts for mmlu_high_school_world_history on rank 0...\n",
      "100%|██████████| 237/237 [00:00<00:00, 433.47it/s]\n",
      "2024-11-18:18:19:54,794 INFO     [task.py:415] Building contexts for mmlu_professional_law on rank 0...\n",
      "100%|██████████| 1534/1534 [00:03<00:00, 428.25it/s]\n",
      "2024-11-18:18:19:58,544 INFO     [task.py:415] Building contexts for arc_challenge on rank 0...\n",
      "100%|██████████| 1172/1172 [00:01<00:00, 739.66it/s]\n",
      "2024-11-18:18:20:00,291 INFO     [evaluator.py:489] Running loglikelihood requests\n",
      "Running loglikelihood requests: 100%|██████████| 247863/247863 [1:17:36<00:00, 53.23it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrapping for stddev: perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 13.94it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrapping for stddev: perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 14.06it/s]\n",
      "2024-11-18:19:42:04,264 WARNING  [huggingface.py:1353] Failed to get model SHA for GPTNeoXForCausalLM(\n",
      "  (gpt_neox): GPTNeoXModel(\n",
      "    (embed_in): Embedding(50304, 768)\n",
      "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x GPTNeoXLayer(\n",
      "        (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (attention): GPTNeoXSdpaAttention(\n",
      "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "          (query_key_value): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): GPTNeoXMLP(\n",
      "          (dense_h_to_4h): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (dense_4h_to_h): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELUActivation()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "  )\n",
      "  (embed_out): Linear(in_features=768, out_features=50304, bias=False)\n",
      ") at revision main. Error: Repo id must be a string, not <class 'transformers.models.gpt_neox.modeling_gpt_neox.GPTNeoXForCausalLM'>: 'GPTNeoXForCausalLM(\n",
      "  (gpt_neox): GPTNeoXModel(\n",
      "    (embed_in): Embedding(50304, 768)\n",
      "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x GPTNeoXLayer(\n",
      "        (input_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (attention): GPTNeoXSdpaAttention(\n",
      "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "          (query_key_value): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): GPTNeoXMLP(\n",
      "          (dense_h_to_4h): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (dense_4h_to_h): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELUActivation()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (rotary_emb): GPTNeoXRotaryEmbedding()\n",
      "  )\n",
      "  (embed_out): Linear(in_features=768, out_features=50304, bias=False)\n",
      ")'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                           Tasks                            |Version|Filter|n-shot|  Metric  |   |    Value    |   |   Stderr   |\n",
      "|------------------------------------------------------------|------:|------|-----:|----------|---|------------:|---|-----------:|\n",
      "|arc_challenge                                               |      1|none  |     0|acc       |↑  |       0.2125|±  |      0.0120|\n",
      "|                                                            |       |none  |     0|acc_norm  |↑  |       0.2679|±  |      0.0129|\n",
      "|blimp                                                       |      2|none  |      |acc       |↑  |       0.5194|±  |      0.0018|\n",
      "| - blimp_adjunct_island                                     |      1|none  |     0|acc       |↑  |       0.6290|±  |      0.0153|\n",
      "| - blimp_anaphor_gender_agreement                           |      1|none  |     0|acc       |↑  |       0.7590|±  |      0.0135|\n",
      "| - blimp_anaphor_number_agreement                           |      1|none  |     0|acc       |↑  |       0.5730|±  |      0.0156|\n",
      "| - blimp_animate_subject_passive                            |      1|none  |     0|acc       |↑  |       0.6220|±  |      0.0153|\n",
      "| - blimp_animate_subject_trans                              |      1|none  |     0|acc       |↑  |       0.7790|±  |      0.0131|\n",
      "| - blimp_causative                                          |      1|none  |     0|acc       |↑  |       0.4080|±  |      0.0155|\n",
      "| - blimp_complex_NP_island                                  |      1|none  |     0|acc       |↑  |       0.4910|±  |      0.0158|\n",
      "| - blimp_coordinate_structure_constraint_complex_left_branch|      1|none  |     0|acc       |↑  |       0.6770|±  |      0.0148|\n",
      "| - blimp_coordinate_structure_constraint_object_extraction  |      1|none  |     0|acc       |↑  |       0.3380|±  |      0.0150|\n",
      "| - blimp_determiner_noun_agreement_1                        |      1|none  |     0|acc       |↑  |       0.5100|±  |      0.0158|\n",
      "| - blimp_determiner_noun_agreement_2                        |      1|none  |     0|acc       |↑  |       0.5120|±  |      0.0158|\n",
      "| - blimp_determiner_noun_agreement_irregular_1              |      1|none  |     0|acc       |↑  |       0.4870|±  |      0.0158|\n",
      "| - blimp_determiner_noun_agreement_irregular_2              |      1|none  |     0|acc       |↑  |       0.5090|±  |      0.0158|\n",
      "| - blimp_determiner_noun_agreement_with_adj_2               |      1|none  |     0|acc       |↑  |       0.5060|±  |      0.0158|\n",
      "| - blimp_determiner_noun_agreement_with_adj_irregular_1     |      1|none  |     0|acc       |↑  |       0.4490|±  |      0.0157|\n",
      "| - blimp_determiner_noun_agreement_with_adj_irregular_2     |      1|none  |     0|acc       |↑  |       0.5120|±  |      0.0158|\n",
      "| - blimp_determiner_noun_agreement_with_adjective_1         |      1|none  |     0|acc       |↑  |       0.4800|±  |      0.0158|\n",
      "| - blimp_distractor_agreement_relational_noun               |      1|none  |     0|acc       |↑  |       0.5190|±  |      0.0158|\n",
      "| - blimp_distractor_agreement_relative_clause               |      1|none  |     0|acc       |↑  |       0.5520|±  |      0.0157|\n",
      "| - blimp_drop_argument                                      |      1|none  |     0|acc       |↑  |       0.6990|±  |      0.0145|\n",
      "| - blimp_ellipsis_n_bar_1                                   |      1|none  |     0|acc       |↑  |       0.4710|±  |      0.0158|\n",
      "| - blimp_ellipsis_n_bar_2                                   |      1|none  |     0|acc       |↑  |       0.3220|±  |      0.0148|\n",
      "| - blimp_existential_there_object_raising                   |      1|none  |     0|acc       |↑  |       0.7090|±  |      0.0144|\n",
      "| - blimp_existential_there_quantifiers_1                    |      1|none  |     0|acc       |↑  |       0.3270|±  |      0.0148|\n",
      "| - blimp_existential_there_quantifiers_2                    |      1|none  |     0|acc       |↑  |       0.6870|±  |      0.0147|\n",
      "| - blimp_existential_there_subject_raising                  |      1|none  |     0|acc       |↑  |       0.4200|±  |      0.0156|\n",
      "| - blimp_expletive_it_object_raising                        |      1|none  |     0|acc       |↑  |       0.6060|±  |      0.0155|\n",
      "| - blimp_inchoative                                         |      1|none  |     0|acc       |↑  |       0.4190|±  |      0.0156|\n",
      "| - blimp_intransitive                                       |      1|none  |     0|acc       |↑  |       0.6020|±  |      0.0155|\n",
      "| - blimp_irregular_past_participle_adjectives               |      1|none  |     0|acc       |↑  |       0.7440|±  |      0.0138|\n",
      "| - blimp_irregular_past_participle_verbs                    |      1|none  |     0|acc       |↑  |       0.4470|±  |      0.0157|\n",
      "| - blimp_irregular_plural_subject_verb_agreement_1          |      1|none  |     0|acc       |↑  |       0.4930|±  |      0.0158|\n",
      "| - blimp_irregular_plural_subject_verb_agreement_2          |      1|none  |     0|acc       |↑  |       0.5420|±  |      0.0158|\n",
      "| - blimp_left_branch_island_echo_question                   |      1|none  |     0|acc       |↑  |       0.5630|±  |      0.0157|\n",
      "| - blimp_left_branch_island_simple_question                 |      1|none  |     0|acc       |↑  |       0.5160|±  |      0.0158|\n",
      "| - blimp_matrix_question_npi_licensor_present               |      1|none  |     0|acc       |↑  |       0.6320|±  |      0.0153|\n",
      "| - blimp_npi_present_1                                      |      1|none  |     0|acc       |↑  |       0.6440|±  |      0.0151|\n",
      "| - blimp_npi_present_2                                      |      1|none  |     0|acc       |↑  |       0.5790|±  |      0.0156|\n",
      "| - blimp_only_npi_licensor_present                          |      1|none  |     0|acc       |↑  |       0.5420|±  |      0.0158|\n",
      "| - blimp_only_npi_scope                                     |      1|none  |     0|acc       |↑  |       0.3320|±  |      0.0149|\n",
      "| - blimp_passive_1                                          |      1|none  |     0|acc       |↑  |       0.7070|±  |      0.0144|\n",
      "| - blimp_passive_2                                          |      1|none  |     0|acc       |↑  |       0.5820|±  |      0.0156|\n",
      "| - blimp_principle_A_c_command                              |      1|none  |     0|acc       |↑  |       0.3080|±  |      0.0146|\n",
      "| - blimp_principle_A_case_1                                 |      1|none  |     0|acc       |↑  |       0.5540|±  |      0.0157|\n",
      "| - blimp_principle_A_case_2                                 |      1|none  |     0|acc       |↑  |       0.4770|±  |      0.0158|\n",
      "| - blimp_principle_A_domain_1                               |      1|none  |     0|acc       |↑  |       0.4730|±  |      0.0158|\n",
      "| - blimp_principle_A_domain_2                               |      1|none  |     0|acc       |↑  |       0.4620|±  |      0.0158|\n",
      "| - blimp_principle_A_domain_3                               |      1|none  |     0|acc       |↑  |       0.5200|±  |      0.0158|\n",
      "| - blimp_principle_A_reconstruction                         |      1|none  |     0|acc       |↑  |       0.3920|±  |      0.0154|\n",
      "| - blimp_regular_plural_subject_verb_agreement_1            |      1|none  |     0|acc       |↑  |       0.4400|±  |      0.0157|\n",
      "| - blimp_regular_plural_subject_verb_agreement_2            |      1|none  |     0|acc       |↑  |       0.5130|±  |      0.0158|\n",
      "| - blimp_sentential_negation_npi_licensor_present           |      1|none  |     0|acc       |↑  |       0.5270|±  |      0.0158|\n",
      "| - blimp_sentential_negation_npi_scope                      |      1|none  |     0|acc       |↑  |       0.2560|±  |      0.0138|\n",
      "| - blimp_sentential_subject_island                          |      1|none  |     0|acc       |↑  |       0.4310|±  |      0.0157|\n",
      "| - blimp_superlative_quantifiers_1                          |      1|none  |     0|acc       |↑  |       0.5080|±  |      0.0158|\n",
      "| - blimp_superlative_quantifiers_2                          |      1|none  |     0|acc       |↑  |       0.9110|±  |      0.0090|\n",
      "| - blimp_tough_vs_raising_1                                 |      1|none  |     0|acc       |↑  |       0.2720|±  |      0.0141|\n",
      "| - blimp_tough_vs_raising_2                                 |      1|none  |     0|acc       |↑  |       0.7090|±  |      0.0144|\n",
      "| - blimp_transitive                                         |      1|none  |     0|acc       |↑  |       0.5390|±  |      0.0158|\n",
      "| - blimp_wh_island                                          |      1|none  |     0|acc       |↑  |       0.8840|±  |      0.0101|\n",
      "| - blimp_wh_questions_object_gap                            |      1|none  |     0|acc       |↑  |       0.0680|±  |      0.0080|\n",
      "| - blimp_wh_questions_subject_gap                           |      1|none  |     0|acc       |↑  |       0.2390|±  |      0.0135|\n",
      "| - blimp_wh_questions_subject_gap_long_distance             |      1|none  |     0|acc       |↑  |       0.4310|±  |      0.0157|\n",
      "| - blimp_wh_vs_that_no_gap                                  |      1|none  |     0|acc       |↑  |       0.4310|±  |      0.0157|\n",
      "| - blimp_wh_vs_that_no_gap_long_distance                    |      1|none  |     0|acc       |↑  |       0.4740|±  |      0.0158|\n",
      "| - blimp_wh_vs_that_with_gap                                |      1|none  |     0|acc       |↑  |       0.5410|±  |      0.0158|\n",
      "| - blimp_wh_vs_that_with_gap_long_distance                  |      1|none  |     0|acc       |↑  |       0.5420|±  |      0.0158|\n",
      "|hellaswag                                                   |      1|none  |     0|acc       |↑  |       0.2582|±  |      0.0044|\n",
      "|                                                            |       |none  |     0|acc_norm  |↑  |       0.2616|±  |      0.0044|\n",
      "|lambada_openai                                              |      1|none  |     0|acc       |↑  |       0.0000|±  |      0.0000|\n",
      "|                                                            |       |none  |     0|perplexity|↓  | 3033175.2693|±  | 288926.5827|\n",
      "|lambada_standard                                            |      1|none  |     0|acc       |↑  |       0.0000|±  |      0.0000|\n",
      "|                                                            |       |none  |     0|perplexity|↓  |27067951.3461|±  |2710040.1909|\n",
      "|mmlu                                                        |      2|none  |      |acc       |↑  |       0.2465|±  |      0.0036|\n",
      "| - humanities                                               |      2|none  |      |acc       |↑  |       0.2451|±  |      0.0063|\n",
      "|  - formal_logic                                            |      1|none  |     0|acc       |↑  |       0.1984|±  |      0.0357|\n",
      "|  - high_school_european_history                            |      1|none  |     0|acc       |↑  |       0.2424|±  |      0.0335|\n",
      "|  - high_school_us_history                                  |      1|none  |     0|acc       |↑  |       0.2353|±  |      0.0298|\n",
      "|  - high_school_world_history                               |      1|none  |     0|acc       |↑  |       0.2616|±  |      0.0286|\n",
      "|  - international_law                                       |      1|none  |     0|acc       |↑  |       0.2479|±  |      0.0394|\n",
      "|  - jurisprudence                                           |      1|none  |     0|acc       |↑  |       0.2963|±  |      0.0441|\n",
      "|  - logical_fallacies                                       |      1|none  |     0|acc       |↑  |       0.2454|±  |      0.0338|\n",
      "|  - moral_disputes                                          |      1|none  |     0|acc       |↑  |       0.2457|±  |      0.0232|\n",
      "|  - moral_scenarios                                         |      1|none  |     0|acc       |↑  |       0.2425|±  |      0.0143|\n",
      "|  - philosophy                                              |      1|none  |     0|acc       |↑  |       0.2733|±  |      0.0253|\n",
      "|  - prehistory                                              |      1|none  |     0|acc       |↑  |       0.2654|±  |      0.0246|\n",
      "|  - professional_law                                        |      1|none  |     0|acc       |↑  |       0.2392|±  |      0.0109|\n",
      "|  - world_religions                                         |      1|none  |     0|acc       |↑  |       0.2105|±  |      0.0313|\n",
      "| - other                                                    |      2|none  |      |acc       |↑  |       0.2687|±  |      0.0079|\n",
      "|  - business_ethics                                         |      1|none  |     0|acc       |↑  |       0.2600|±  |      0.0441|\n",
      "|  - clinical_knowledge                                      |      1|none  |     0|acc       |↑  |       0.2679|±  |      0.0273|\n",
      "|  - college_medicine                                        |      1|none  |     0|acc       |↑  |       0.2081|±  |      0.0310|\n",
      "|  - global_facts                                            |      1|none  |     0|acc       |↑  |       0.3100|±  |      0.0465|\n",
      "|  - human_aging                                             |      1|none  |     0|acc       |↑  |       0.3767|±  |      0.0325|\n",
      "|  - management                                              |      1|none  |     0|acc       |↑  |       0.2524|±  |      0.0430|\n",
      "|  - marketing                                               |      1|none  |     0|acc       |↑  |       0.2564|±  |      0.0286|\n",
      "|  - medical_genetics                                        |      1|none  |     0|acc       |↑  |       0.2600|±  |      0.0441|\n",
      "|  - miscellaneous                                           |      1|none  |     0|acc       |↑  |       0.2874|±  |      0.0162|\n",
      "|  - nutrition                                               |      1|none  |     0|acc       |↑  |       0.2288|±  |      0.0241|\n",
      "|  - professional_accounting                                 |      1|none  |     0|acc       |↑  |       0.2553|±  |      0.0260|\n",
      "|  - professional_medicine                                   |      1|none  |     0|acc       |↑  |       0.2022|±  |      0.0244|\n",
      "|  - virology                                                |      1|none  |     0|acc       |↑  |       0.3193|±  |      0.0363|\n",
      "| - social sciences                                          |      2|none  |      |acc       |↑  |       0.2343|±  |      0.0076|\n",
      "|  - econometrics                                            |      1|none  |     0|acc       |↑  |       0.2807|±  |      0.0423|\n",
      "|  - high_school_geography                                   |      1|none  |     0|acc       |↑  |       0.2172|±  |      0.0294|\n",
      "|  - high_school_government_and_politics                     |      1|none  |     0|acc       |↑  |       0.2073|±  |      0.0293|\n",
      "|  - high_school_macroeconomics                              |      1|none  |     0|acc       |↑  |       0.2205|±  |      0.0210|\n",
      "|  - high_school_microeconomics                              |      1|none  |     0|acc       |↑  |       0.2311|±  |      0.0274|\n",
      "|  - high_school_psychology                                  |      1|none  |     0|acc       |↑  |       0.2367|±  |      0.0182|\n",
      "|  - human_sexuality                                         |      1|none  |     0|acc       |↑  |       0.2290|±  |      0.0369|\n",
      "|  - professional_psychology                                 |      1|none  |     0|acc       |↑  |       0.2565|±  |      0.0177|\n",
      "|  - public_relations                                        |      1|none  |     0|acc       |↑  |       0.3455|±  |      0.0455|\n",
      "|  - security_studies                                        |      1|none  |     0|acc       |↑  |       0.1714|±  |      0.0241|\n",
      "|  - sociology                                               |      1|none  |     0|acc       |↑  |       0.2388|±  |      0.0301|\n",
      "|  - us_foreign_policy                                       |      1|none  |     0|acc       |↑  |       0.2100|±  |      0.0409|\n",
      "| - stem                                                     |      2|none  |      |acc       |↑  |       0.2388|±  |      0.0076|\n",
      "|  - abstract_algebra                                        |      1|none  |     0|acc       |↑  |       0.2600|±  |      0.0441|\n",
      "|  - anatomy                                                 |      1|none  |     0|acc       |↑  |       0.2519|±  |      0.0375|\n",
      "|  - astronomy                                               |      1|none  |     0|acc       |↑  |       0.1842|±  |      0.0315|\n",
      "|  - college_biology                                         |      1|none  |     0|acc       |↑  |       0.2222|±  |      0.0348|\n",
      "|  - college_chemistry                                       |      1|none  |     0|acc       |↑  |       0.2100|±  |      0.0409|\n",
      "|  - college_computer_science                                |      1|none  |     0|acc       |↑  |       0.1500|±  |      0.0359|\n",
      "|  - college_mathematics                                     |      1|none  |     0|acc       |↑  |       0.2300|±  |      0.0423|\n",
      "|  - college_physics                                         |      1|none  |     0|acc       |↑  |       0.1961|±  |      0.0395|\n",
      "|  - computer_security                                       |      1|none  |     0|acc       |↑  |       0.2400|±  |      0.0429|\n",
      "|  - conceptual_physics                                      |      1|none  |     0|acc       |↑  |       0.3234|±  |      0.0306|\n",
      "|  - electrical_engineering                                  |      1|none  |     0|acc       |↑  |       0.2207|±  |      0.0346|\n",
      "|  - elementary_mathematics                                  |      1|none  |     0|acc       |↑  |       0.2566|±  |      0.0225|\n",
      "|  - high_school_biology                                     |      1|none  |     0|acc       |↑  |       0.2548|±  |      0.0248|\n",
      "|  - high_school_chemistry                                   |      1|none  |     0|acc       |↑  |       0.2709|±  |      0.0313|\n",
      "|  - high_school_computer_science                            |      1|none  |     0|acc       |↑  |       0.2300|±  |      0.0423|\n",
      "|  - high_school_mathematics                                 |      1|none  |     0|acc       |↑  |       0.2630|±  |      0.0268|\n",
      "|  - high_school_physics                                     |      1|none  |     0|acc       |↑  |       0.1987|±  |      0.0326|\n",
      "|  - high_school_statistics                                  |      1|none  |     0|acc       |↑  |       0.1620|±  |      0.0251|\n",
      "|  - machine_learning                                        |      1|none  |     0|acc       |↑  |       0.2857|±  |      0.0429|\n",
      "|winogrande                                                  |      1|none  |     0|acc       |↑  |       0.4933|±  |      0.0141|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Evaluation - Pythia 160M Trained on MiniPile\n",
    "\n",
    "pythia_minipile = AutoModelForCausalLM.from_pretrained(base_path / \"pythia160m_minipile_trained\", local_files_only=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_path / \"pythia160m_dedup_untrained\", use_fast=True, local_files_only=True) # Use exact same tokenizer\n",
    "pythia_minipile = pythia_minipile.to(device)\n",
    " \n",
    "batch_size_hflm = 1\n",
    "\n",
    "pythia_minipile_hflm = HFLM(pretrained=pythia_minipile,\n",
    "                        tokenizer=tokenizer,\n",
    "                        batch_size=batch_size_hflm)\n",
    "\n",
    "results = simple_evaluate(model=pythia_minipile_hflm,\n",
    "                          tasks=[\"arc_challenge\", \"mmlu\", \"winogrande\", \"hellaswag\", \"lambada\", \"blimp\"],\n",
    "                          num_fewshot=0,\n",
    "                          batch_size=batch_size_hflm,\n",
    "                          device=\"cuda\",\n",
    "                          limit=None)\n",
    "\n",
    "with open('02_eval_160M_minipile.txt', 'w') as f:\n",
    "    f.write(str(results))\n",
    "\n",
    "print(utils.make_table(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the catch?\n",
    "\n",
    "I calculated the \"Percentage Difference of Means\" and \"95% Confidence Interval\" in the `MiniPile_Pile_Benchmark_Comparisons.ods` spreadsheet.<br>\n",
    "Crucially, we see the following results for the MiniPile-trained Pythia $160M$ model, compared against the Pile-trained Pythia $160M$ model:\n",
    "\n",
    "| Benchmark        | Measure      |   | 160M Pile Deduplicated | 160M MiniPile               | Percentage Difference of Means | 95% Confidence Interval        | Interpretation                            |\n",
    "| ---------------- | ------------ | - | ---------------------- | --------------------------- | ------------------------------ | ------------------------------ | ----------------------------------------- |\n",
    "| ARC-Challenge    | acc          | ↑ | 0.1997 ± 0.0117        | **0.2125 ± 0.0120**         | 6.4096                         | (0.0456; -0.0200)              | Difference not significant                |\n",
    "| MMLU             | acc          | ↑ | 0.2299 ± 0.0035        | **0.2699 ± 0.0037**         | 17.3989                        | (0.0500; 0.0300)               | **MiniPile-trained better**               |\n",
    "| HellaSwag        | acc          | ↑ | **0.2903 ± 0.0045**    | 0.2560 ± 0.0044             | -11.8154                       | (-0.0220; -0.0466)             | Pile Deduplicated-trained better          |\n",
    "| WinoGrande       | acc          | ↑ | **0.4964 ± 0.0141**    | 0.4720 ± 0.0140             | -4.9154                        | (0.0145; -0.0633)              | Difference not significant                |\n",
    "| Lambada (OpenAI) | acc          | ↑ | **0.3689 ± 0.0067**    | 0.0000 ± 0.0000             | -100.00                        | (-0.3558; -0.3820)             | Pile Deduplicated-trained severely better |\n",
    "| Lambada (OpenAI) | perplexity   | ↓ | **31.2589 ± 1.1594**   | 3033175.2693 ± 288926.5827  | 9703297.3342                   | (3599440.1125; 2466847.9083)   | Pile Deduplicated-trained severely better |\n",
    "| Lambada (Std)    | acc          | ↑ | **0.2335 ± 0.0059**    | 0.0000 ± 0.0000             | -100.00                        | (-0.2219; -0.2451)             | Pile Deduplicated-trained severely better |\n",
    "| Lambada (Std)    | perplexity   | ↓ | **172.7619 ± 7.7265**  | 27067951.3460 ± 2710040.191 | 15667678.2231                  | (32379457.3584; 21756099.8100) | Pile Deduplicated-trained severely better |\n",
    "| BLiMP            | acc          | ↑ | **0.7294 ± 0.0015**    | 0.5194 ± 0.0018             | -28.7908                       | (-0,2054; -0,2146)             | Pile Deduplicated-trained better          |\n",
    "\n",
    "- Training pipeline replication seems successful, as the MiniPile-trained model displays competitive performance on multiple benchmarks.\n",
    "    - Performance significantly better on MMLU\n",
    "    - Comparable performance on ARC-Challenge, WinoGrande\n",
    "    - Inferior performance on HellaSwag\n",
    "    - Severely inferior performance on Lambada (OpenAI)\n",
    "\n",
    "I interpret the results for the Lambada benchmark as follows:\n",
    "- MiniPile seems to lack distinctly crucial linguistic understanding that was certainly emitted from The Pile Deduplicated\n",
    "- It seems general linguistic understanding on MiniPile, given the extremely high perplexity, is severely lacking\n",
    "\n",
    "Therefore, while MiniPile can enable competitive performance on some tasks with three orders of magnitude less data, it seems to break down in capturing more general aspects of language necessary for those benchmarks involving next-token prediction in rather context-rich settings.\n",
    "\n",
    "**In other words:** There indeed seems to be no free lunch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minipile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
